# 장년층 이력서 생성 도우미 - 개발 테스크

---

## 📋 프로젝트 개요
- **목표**: 50대 이상 장년층을 위한 AI 기반 이력서 생성 및 채용 매칭 플랫폼
- **개발 기간**: 6개월 (4단계)
- **개발 환경**: 1인 풀스택, 온프레미스 서버 1대

---

## 테스크 실행 규칙

**규칙 내용**
1. 테스크 목록 코딩을 시작하되, 한 번에 딱 하나씩만 실행한다.
2. 하나의 테스크가 끝날 때마다 멈춰서 사용자에게 허락을 받는다.
3. 작업 완료 시 체크박스에 표시하도록 명령한다.
4. 하나의 테스크가 끝나기전까지는 허락 없이 진행한다.
5. 불필요한 이모티콘은 포함하지 않는다.
6. 테스트파일은 완료후 삭제한다.

## 🎯 Phase 1: MVP (최소 기능 제품) - 2개월

### Week 1-2: 프로젝트 초기화 (인프라 기 완료)
<!-- ✅ 서버 환경 설정 (완료)
  ✅ Ubuntu 서버 설치 및 기본 설정
  ✅ Docker 및 Docker Compose 설치  
  ✅ Nginx 설치 및 기본 설정
  
✅ 데이터베이스 설정 (완료)
  ✅ PostgreSQL 서버 실행 (Host: 114.202.2.226:5433)
  ✅ 데이터베이스 생성 및 사용자 설정 (DB: postgres, Schema: mlops)
  ✅ 기본 연결 테스트 -->

- [x] 백엔드 프로젝트 초기화
  - [x] Python 3.10+ 환경 설정
  - [x] FastAPI 프로젝트 생성
  - [x] requirements.txt 작성 (FastAPI, SQLAlchemy, psycopg2 등)
  - [x] 기본 디렉토리 구조 생성
  - [x] Docker Compose 설정 파일 작성
  - [x] 환경 변수 설정 (.env)
    - [x] 데이터베이스 연결 정보 설정 (Host: 114.202.2.226:5433, DB: postgres, Schema: mlops)

- [x] 프론트엔드 프로젝트 초기화
  - [x] Node.js 및 npm 설치
  - [x] React 18+ 프로젝트 생성
  - [x] 필요 패키지 설치 (Material-UI)
  - [x] 기본 컴포넌트 구조 설계
  - [x] 개발 서버 실행 테스트

- [x] PostgreSQL 테이블 스키마 설계 및 생성
  - [x] 기존 DB 연결 확인 (114.202.2.226:5433, mlops 스키마)
  - [x] mlops.resumes 테이블 생성
  - [x] mlops.cover_letters 테이블 생성
  - [x] mlops.job_postings 테이블 생성
  - [x] mlops.prediction_logs 테이블 생성
  - [x] SQLAlchemy 모델 작성 (스키마 경로 포함)
  - [x] Alembic 마이그레이션 설정 (기존 DB 연동)

### Week 3-4: 데이터 수집 시스템
- [x] 크롤링 인프라 구축
  - [x] Scrapy 또는 BeautifulSoup 설치
  - [x] 기본 크롤러 클래스 설계
  - [x] robots.txt 준수 로직 구현
  - [x] Rate limiting 구현
  - [x] 에러 핸들링 및 재시도 로직

- [x] 사람인 크롤러 개발
  - [x] 채용공고 목록 크롤링
  - [x] 개별 공고 상세 정보 크롤링
  - [x] 50대 이상 관련 키워드 필터링
  - [x] 데이터 검증 로직 구현

- [x] Linkareer 크롤러 개발
  - [x] 자기소개서 목록 크롤링
  - [x] 개별 자기소개서 내용 크롤링
  - [x] 회사명, 직무별 분류
  - [x] 합격/불합격 정보 추출 (가능한 경우)

- [ ] 데이터 처리 및 저장
  - [x] HTML 태그 제거 및 텍스트 정제
  - [x] 중복 데이터 제거 로직
  - [ ] PostgreSQL 저장 로직 (mlops 스키마 대상)
  - [ ] 데이터 검증 및 품질 체크

- [ ] Airflow 기본 설정
  - [ ] Apache Airflow 설치
  - [ ] 기본 DAG 생성 (데이터 수집용)
  - [ ] 스케줄링 설정 (매일 새벽 2시)
  - [ ] 웹 UI 접근 설정

### Week 5-6: 핵심 AI 기능 구현
- [ ] OpenAI API 설정
  - [ ] OpenAI API 키 설정
  - [ ] GPT-4 API 연동 테스트
  - [ ] 토큰 사용량 모니터링 설정
  - [ ] 비용 제한 설정

- [ ] Whisper 모델 배포
  - [ ] OpenAI Whisper 로컬 설치
  - [ ] GPU 가속 설정 확인
  - [ ] 음성 파일 업로드 API 구현
  - [ ] STT 변환 API 구현
  - [ ] 한국어 인식 정확도 테스트

- [ ] 이력서 생성 로직
  - [ ] GPT-4 프롬프트 템플릿 작성
  - [ ] 사용자 입력 → 구조화된 데이터 변환
  - [ ] 음성 텍스트 → 이력서 데이터 변환
  - [ ] 생성된 이력서 포맷팅

- [ ] 자기소개서 생성 로직
  - [ ] 채용공고 + 이력서 분석 프롬프트 작성
  - [ ] 맞춤형 자기소개서 생성 API
  - [ ] 키포인트 추출 기능
  - [ ] 생성 결과 검증 로직

- [ ] 기본 매칭 알고리즘
  - [ ] TF-IDF 기반 유사도 계산
  - [ ] 간단한 점수 산출 로직
  - [ ] 매칭 확률 API 구현 (임시)

### Week 7-8: 웹 인터페이스 개발
- [ ] 백엔드 API 구현
  - [ ] 이력서 CRUD API
  - [ ] 음성 업로드 API
  - [ ] 이력서 생성 API
  - [ ] 자기소개서 생성 API
  - [ ] 채용공고 조회 API
  - [ ] 매칭 확률 API

- [ ] 프론트엔드 페이지 구현
  - [ ] 메인 랜딩 페이지
  - [ ] 이력서 입력 폼 페이지
  - [ ] 음성 녹음 인터페이스
  - [ ] 생성된 이력서 표시 페이지
  - [ ] 자기소개서 생성 페이지
  - [ ] 채용공고 목록 페이지

- [ ] UI/UX 개선 (장년층 친화적)
  - [ ] 큰 폰트 사이즈 적용
  - [ ] 직관적인 네비게이션
  - [ ] 명확한 버튼 텍스트
  - [ ] 도움말 및 가이드 추가

- [ ] 기본 테스트
  - [ ] 전체 플로우 테스트
  - [ ] 음성 입력 → 이력서 생성 테스트
  - [ ] 웹 폼 입력 → 이력서 생성 테스트
  - [ ] 자기소개서 생성 테스트

### Week 8: MVP 검증 및 배포
- [ ] 통합 테스트
  - [ ] 전체 시스템 연동 테스트
  - [ ] 성능 테스트 (응답 시간)
  - [ ] 오류 처리 테스트

- [ ] 배포 준비
  - [ ] Production 환경 설정
  - [ ] 환경 변수 분리
  - [ ] 로그 설정
  - [ ] 백업 스크립트 작성

- [ ] MVP 출시
  - [ ] 소규모 테스트 유저 초대
  - [ ] 피드백 수집 시스템 구축
  - [ ] 사용량 모니터링 기본 설정

---

## 🚀 Phase 2: ML 모델 개발 - 2개월

### Week 9-10: 데이터 준비 및 전처리
- [ ] 데이터 수집 상태 점검
  - [ ] 채용공고 데이터 5,000건 이상 확보
  - [ ] 자기소개서 데이터 1,000건 이상 확보
  - [ ] 데이터 품질 점검 및 정제

- [ ] 데이터 라벨링
  - [ ] 합격/불합격 데이터 라벨링 전략 수립
  - [ ] 수동 라벨링 도구 개발 (간단한 웹 인터페이스)
  - [ ] 크라우드소싱 라벨링 검토 (선택사항)
  - [ ] 최소 1,000건 라벨링 완료

- [ ] Feature Engineering
  - [ ] 텍스트 전처리 파이프라인 구축
  - [ ] Sentence-BERT 임베딩 생성
  - [ ] 키워드 추출 (TF-IDF, 품사 태깅)
  - [ ] 경력, 학력, 스킬 정규화

- [ ] 데이터셋 분할
  - [ ] Train/Validation/Test 분할 (60/20/20)
  - [ ] 계층 샘플링 적용
  - [ ] 데이터 불균형 처리 방안 수립

### Week 11-12: 합격률 예측 모델 개발
- [ ] 베이스라인 모델 구축
  - [ ] 간단한 로지스틱 회귀 모델
  - [ ] Random Forest 모델
  - [ ] 기본 성능 지표 측정 (Accuracy, F1, ROC-AUC)

- [ ] 딥러닝 모델 실험
  - [ ] BERT 기반 분류 모델
  - [ ] 이력서-공고 매칭용 Siamese Network
  - [ ] Transformer 기반 매칭 모델

- [ ] 모델 최적화
  - [ ] 하이퍼파라미터 튜닝 (Grid Search, Random Search)
  - [ ] 교차 검증 (Cross Validation)
  - [ ] 앙상블 방법 적용

- [ ] 모델 평가 및 선택
  - [ ] 테스트 데이터 성능 평가
  - [ ] 혼동 행렬 (Confusion Matrix) 분석
  - [ ] 특성 중요도 분석
  - [ ] 최종 모델 선택

### Week 13-14: 추천 시스템 개발
- [ ] 채용공고 추천 모델
  - [ ] Content-based 필터링 구현
  - [ ] 협업 필터링 구현 (사용자 데이터 충분시)
  - [ ] 하이브리드 추천 시스템 구축
  - [ ] 추천 다양성 및 참신성 고려

- [ ] 직무 추천 모델
  - [ ] 경력 분석 알고리즘
  - [ ] 스킬-직무 매핑 테이블 구축
  - [ ] 유사 사용자 기반 추천
  - [ ] 추천 결과 랭킹 알고리즘

- [ ] 모델 서빙 인프라
  - [ ] TorchServe 설치 및 설정
  - [ ] 모델 배포 스크립트 작성
  - [ ] REST API 엔드포인트 구축
  - [ ] 배치 예측 vs 실시간 예측 전략

- [ ] 성능 최적화
  - [ ] 모델 추론 속도 최적화
  - [ ] 캐싱 전략 구현
  - [ ] 병렬 처리 구현

### Week 15-16: MLflow 연동 및 실험 관리
- [ ] MLflow 설치 및 설정
  - [ ] MLflow Tracking Server 설치
  - [ ] SQLite/PostgreSQL 백엔드 설정
  - [ ] 아티팩트 스토어 설정 (로컬 파일시스템)
  - [ ] 웹 UI 접근 설정

- [ ] 실험 추적 시스템 구축
  - [ ] 모델 학습 코드에 MLflow 연동
  - [ ] 하이퍼파라미터 로깅
  - [ ] 메트릭 로깅 (정확도, 손실 등)
  - [ ] 모델 아티팩트 저장

- [ ] Model Registry 구성
  - [ ] 모델 등록 자동화
  - [ ] 모델 버전 관리
  - [ ] Staging/Production 단계 설정
  - [ ] 모델 승격 기준 정의

- [ ] Airflow에서 MLflow 연동
  - [ ] 모델 학습 DAG 작성
  - [ ] 조건부 실행 로직 (신규 데이터 임계값)
  - [ ] 모델 평가 및 등록 자동화
  - [ ] 실패 시 알림 설정

---

## 📊 Phase 3: MLOps 고도화 - 1.5개월

### Week 17-18: 모니터링 시스템 구축
- [ ] Prometheus 설치 및 설정
  - [ ] Prometheus 서버 설치
  - [ ] 메트릭 수집 설정
  - [ ] Node Exporter 설치 (시스템 메트릭)
  - [ ] GPU 모니터링 설정

- [ ] 애플리케이션 메트릭 구현
  - [ ] FastAPI에 Prometheus 메트릭 추가
  - [ ] 예측 요청 횟수 카운터
  - [ ] 응답 시간 히스토그램
  - [ ] 모델 정확도 게이지
  - [ ] 에러율 메트릭

- [ ] Grafana 대시보드 구성
  - [ ] Grafana 설치 및 Prometheus 연동
  - [ ] 모델 성능 대시보드 생성
  - [ ] 시스템 리소스 대시보드 생성
  - [ ] 데이터 품질 대시보드 생성
  - [ ] 비즈니스 메트릭 대시보드 생성

- [ ] 알림 시스템 설정
  - [ ] Grafana 알림 규칙 설정
  - [ ] 이메일/Slack 알림 연동
  - [ ] 임계값 기반 알림 (정확도 하락, 시스템 오류)
  - [ ] 알림 에스컬레이션 정책

### Week 19-20: 자동화 파이프라인 구축
- [ ] 완전 자동화 파이프라인 구축
  - [ ] 데이터 수집 → 전처리 → 학습 → 배포 통합
  - [ ] 파이프라인 의존성 관리
  - [ ] 중간 실패 시 롤백 전략
  - [ ] 수동 승인 단계 (Production 배포)

- [ ] 모델 재학습 트리거 시스템
  - [ ] 신규 데이터 임계값 모니터링
  - [ ] 모델 성능 저하 감지
  - [ ] 자동 재학습 스케줄링
  - [ ] 리소스 사용량 기반 스케줄링

- [ ] A/B 테스트 인프라 (선택사항)
  - [ ] 트래픽 분할 로직
  - [ ] 실험 그룹 관리
  - [ ] 통계적 유의성 검정
  - [ ] 실험 결과 자동 분석

- [ ] 데이터 드리프트 감지
  - [ ] 입력 데이터 분포 모니터링
  - [ ] KS-test, Jensen-Shannon divergence 구현
  - [ ] 드리프트 감지 시 알림
  - [ ] 자동 재학습 트리거

### Week 21-22: 이력서 개선 기능 개발
- [ ] 이력서 분석 엔진
  - [ ] GPT-4 기반 이력서 분석 프롬프트 최적화
  - [ ] 키워드 밀도 분석
  - [ ] 문장 구조 분석
  - [ ] 성과 지표 추출 로직

- [ ] 개선 제안 시스템
  - [ ] 개선 카테고리 정의 (키워드, 성과, 구조 등)
  - [ ] 개선 제안 우선순위 알고리즘
  - [ ] 구체적인 예시 제공 로직
  - [ ] 개선 전후 비교 기능

- [ ] 합격 패턴 분석
  - [ ] 성공 이력서 패턴 추출 알고리즘
  - [ ] 직무별 핵심 키워드 분석
  - [ ] 업계 트렌드 반영 로직
  - [ ] 통계 기반 인사이트 생성

- [ ] 트렌드 분석 시스템
  - [ ] 최신 채용공고 키워드 트렌드 분석
  - [ ] 월별/분기별 트렌드 변화 추적
  - [ ] 업계별 요구사항 변화 분석
  - [ ] 트렌드 기반 이력서 업데이트 제안

---

## ⚡ Phase 4: 고급 기능 및 최적화 - 1개월

### Week 23-24: 성능 최적화
- [ ] API 성능 최적화
  - [ ] 데이터베이스 쿼리 최적화
  - [ ] 인덱스 추가 및 최적화
  - [ ] 연결 풀링 설정
  - [ ] 쿼리 캐싱 구현

- [ ] 캐싱 전략 구현
  - [ ] Redis 설치 및 설정
  - [ ] API 응답 캐싱
  - [ ] 모델 예측 결과 캐싱
  - [ ] 자주 조회되는 데이터 캐싱

- [ ] 모델 추론 최적화
  - [ ] 모델 양자화 (Quantization)
  - [ ] ONNX 변환 검토
  - [ ] TensorRT 최적화 (GPU)
  - [ ] 배치 추론 구현

- [ ] 시스템 리소스 최적화
  - [ ] 메모리 사용량 최적화
  - [ ] CPU 사용률 최적화
  - [ ] GPU 메모리 관리 개선
  - [ ] 디스크 I/O 최적화

### Week 25-26: 사용자 경험 개선
- [ ] UI/UX 고도화
  - [ ] 장년층 접근성 개선
  - [ ] 화면 읽기 프로그램 지원
  - [ ] 키보드 네비게이션 최적화
  - [ ] 고대비 모드 지원

- [ ] 모바일 최적화
  - [ ] 반응형 디자인 구현
  - [ ] 터치 인터페이스 최적화
  - [ ] 모바일 음성 입력 최적화
  - [ ] 모바일 성능 최적화

- [ ] 사용자 가이드 시스템
  - [ ] 인터랙티브 튜토리얼 구현
  - [ ] 단계별 가이드 제공
  - [ ] 도움말 시스템 구축
  - [ ] FAQ 페이지 작성

- [ ] 에러 처리 및 사용자 피드백
  - [ ] 친화적인 에러 메시지
  - [ ] 에러 복구 가이드
  - [ ] 사용자 피드백 수집 시스템
  - [ ] 버그 리포트 시스템

### Week 26: 최종 검증 및 배포
- [ ] 전체 시스템 테스트
  - [ ] 부하 테스트 (Load Testing)
  - [ ] 스트레스 테스트 (Stress Testing)
  - [ ] 보안 테스트
  - [ ] 접근성 테스트

- [ ] 최종 배포 준비
  - [ ] Production 환경 최종 점검
  - [ ] 백업 및 복구 절차 테스트
  - [ ] 모니터링 대시보드 최종 점검
  - [ ] 운영 매뉴얼 작성

- [ ] 베타 테스트
  - [ ] 실제 사용자 베타 테스트
  - [ ] 피드백 수집 및 분석
  - [ ] 긴급 수정사항 반영
  - [ ] 정식 출시 준비

---

## 🔧 지속적 운영 및 개선

### 운영 체크리스트
- [ ] 일일 시스템 상태 점검
- [ ] 주간 데이터 품질 리포트 생성
- [ ] 월간 모델 성능 분석
- [ ] 분기별 사용자 만족도 조사

### 개선 작업
- [ ] 사용자 피드백 기반 기능 개선
- [ ] 새로운 데이터 소스 추가
- [ ] 추가 ML 모델 개발 (연봉 예측, 면접 준비 등)
- [ ] 모바일 앱 개발 고려

### 확장 가능성
- [ ] 클라우드 마이그레이션 계획
- [ ] 마이크로서비스 아키텍처 전환
- [ ] 다국가 서비스 확장
- [ ] B2B 서비스 모델 검토

---

## 📊 성과 측정

### 개발 완료 기준
- [ ] MVP 기능 100% 구현
- [ ] 모델 정확도 75% 이상 달성
- [ ] API 응답 시간 P95 < 2초
- [ ] 시스템 가동률 99% 이상
- [ ] 사용자 만족도 NPS 50 이상

### 주요 KPI 체크
- [ ] 일일 활성 사용자 100명 달성
- [ ] 월간 이력서 생성 500건 달성
- [ ] 추천 공고 클릭률 30% 달성
- [ ] 데이터 수집 성공률 95% 달성

---

## ⚠️ 리스크 관리

### 기술적 리스크 대응
- [ ] 단일 서버 장애 대응 계획 수립
- [ ] GPU 메모리 부족 시 대응 방안
- [ ] 크롤링 차단 시 우회 전략
- [ ] API 비용 급증 시 대응 방안

### 데이터 리스크 대응
- [ ] 개인정보 보호 조치 구현
- [ ] 데이터 품질 모니터링 시스템
- [ ] 편향된 데이터 감지 및 대응

### 비즈니스 리스크 대응
- [ ] 사용자 확보 전략 수립
- [ ] 경쟁사 분석 및 차별화 전략
- [ ] 수익 모델 다양화 계획

---

## 📝 문서화

### 기술 문서
- [ ] API 문서 (OpenAPI/Swagger)
- [ ] 데이터베이스 스키마 문서
- [ ] 모델 아키텍처 문서
- [ ] 배포 가이드 문서

### 운영 문서
- [ ] 시스템 운영 매뉴얼
- [ ] 트러블슈팅 가이드
- [ ] 백업 및 복구 절차
- [ ] 보안 정책 문서

### 사용자 문서
- [ ] 사용자 가이드
- [ ] FAQ 문서
- [ ] 개인정보 처리방침
- [ ] 서비스 이용약관

---

**작업 진행 방법:**
1. 각 체크박스를 완료하면 `[x]`로 표시
2. 진행 중인 작업은 `[~]`로 표시
3. 차단된 작업은 `[!]`로 표시하고 이유 기록
4. 주간 단위로 진행 상황 검토 및 업데이트

**우선순위 표시:**
- 🔴 긴급 (즉시 처리 필요)
- 🟡 중요 (우선순위 높음)
- 🟢 일반 (스케줄대로 진행)
- 🔵 선택사항 (시간 여유시 진행)