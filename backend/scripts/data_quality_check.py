#!/usr/bin/env python3
"""
ë°ì´í„° í’ˆì§ˆ ì ê²€ ë° ì •ì œ ìŠ¤í¬ë¦½íŠ¸
- ì±„ìš©ê³µê³  ë° ìê¸°ì†Œê°œì„œ ë°ì´í„° í’ˆì§ˆ ì ê²€
- ê²°ì¸¡ì¹˜, ì¤‘ë³µ, ì´ìƒì¹˜ íƒì§€
- ë°ì´í„° ì •ì œ ë° ì •ê·œí™”
"""
import sys
import os
from datetime import datetime

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€
project_path = '/home/ttm/tensorflow-jupyter/jupyterNotebook/khj/mlops-platform'
sys.path.insert(0, project_path)

from sqlalchemy import create_engine, text
from dotenv import load_dotenv
import re

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
DATABASE_URL = os.getenv("DATABASE_URL")


def check_job_postings_quality():
    """ì±„ìš©ê³µê³  ë°ì´í„° í’ˆì§ˆ ì ê²€"""
    engine = create_engine(DATABASE_URL)
    
    print("\n" + "=" * 80)
    print("ğŸ“Š ì±„ìš©ê³µê³  ë°ì´í„° í’ˆì§ˆ ì ê²€")
    print("=" * 80)
    
    with engine.connect() as conn:
        # ì „ì²´ í†µê³„
        result = conn.execute(text('''
            SELECT 
                COUNT(*) as total,
                COUNT(DISTINCT company) as unique_companies,
                COUNT(DISTINCT source_url) as unique_urls,
                COUNT(CASE WHEN title IS NULL OR title = '' THEN 1 END) as missing_title,
                COUNT(CASE WHEN company IS NULL OR company = '' THEN 1 END) as missing_company,
                COUNT(CASE WHEN description IS NULL OR description = '' THEN 1 END) as missing_description,
                COUNT(CASE WHEN source_url IS NULL OR source_url = '' THEN 1 END) as missing_url,
                COUNT(CASE WHEN location IS NULL OR location = '' THEN 1 END) as missing_location,
                COUNT(CASE WHEN employment_type IS NULL OR employment_type = '' THEN 1 END) as missing_employment_type,
                AVG(LENGTH(description)) as avg_desc_length,
                MIN(LENGTH(description)) as min_desc_length,
                MAX(LENGTH(description)) as max_desc_length
            FROM mlops.job_postings
        '''))
        
        row = result.fetchone()
        print(f'\nê¸°ë³¸ í†µê³„:')
        print(f'  ì „ì²´ ë°ì´í„°: {row.total}ê±´')
        print(f'  ê³ ìœ  íšŒì‚¬: {row.unique_companies}ê°œ')
        print(f'  ê³ ìœ  URL: {row.unique_urls}ê°œ')
        print(f'  ì¤‘ë³µë¥ : {(row.total - row.unique_urls) / row.total * 100:.1f}%')
        
        print(f'\nê²°ì¸¡ì¹˜:')
        print(f'  - ì œëª© ëˆ„ë½: {row.missing_title}ê±´ ({row.missing_title/row.total*100:.1f}%)')
        print(f'  - íšŒì‚¬ëª… ëˆ„ë½: {row.missing_company}ê±´ ({row.missing_company/row.total*100:.1f}%)')
        print(f'  - ì„¤ëª… ëˆ„ë½: {row.missing_description}ê±´ ({row.missing_description/row.total*100:.1f}%)')
        print(f'  - URL ëˆ„ë½: {row.missing_url}ê±´ ({row.missing_url/row.total*100:.1f}%)')
        print(f'  - ìœ„ì¹˜ ëˆ„ë½: {row.missing_location}ê±´ ({row.missing_location/row.total*100:.1f}%)')
        print(f'  - ê³ ìš©í˜•íƒœ ëˆ„ë½: {row.missing_employment_type}ê±´ ({row.missing_employment_type/row.total*100:.1f}%)')
        
        print(f'\nì„¤ëª… ê¸¸ì´ í†µê³„:')
        print(f'  - í‰ê· : {row.avg_desc_length:.0f}ì')
        print(f'  - ìµœì†Œ: {row.min_desc_length}ì')
        print(f'  - ìµœëŒ€: {row.max_desc_length}ì')
        
        # ì¤‘ë³µ URL í™•ì¸
        result = conn.execute(text('''
            SELECT source_url, COUNT(*) as count, 
                   array_agg(id) as ids,
                   MAX(created_at) as latest_created
            FROM mlops.job_postings
            WHERE source_url IS NOT NULL AND source_url != ''
            GROUP BY source_url
            HAVING COUNT(*) > 1
            ORDER BY count DESC
            LIMIT 10
        '''))
        
        duplicates = result.fetchall()
        print(f'\nì¤‘ë³µ URL: {len(duplicates)}ê°œ')
        if duplicates:
            print('  ìƒìœ„ 10ê°œ:')
            for dup in duplicates:
                print(f'    - {dup.source_url[:70]}... ({dup.count}ê±´)')
                print(f'      IDs: {dup.ids}')
        
        # ë¹„ì •ìƒì ìœ¼ë¡œ ì§§ì€ ì„¤ëª…
        result = conn.execute(text('''
            SELECT id, title, company, LENGTH(description) as desc_len
            FROM mlops.job_postings
            WHERE LENGTH(description) < 100
            ORDER BY desc_len
            LIMIT 10
        '''))
        
        short_desc = result.fetchall()
        print(f'\në¹„ì •ìƒì ìœ¼ë¡œ ì§§ì€ ì„¤ëª… (< 100ì): {len(short_desc)}ê±´')
        if short_desc:
            for sd in short_desc:
                print(f'    - ID {sd.id}: {sd.company} - {sd.title} ({sd.desc_len}ì)')
        
        # ë‚ ì§œë³„ ë°ì´í„° ë¶„í¬
        result = conn.execute(text('''
            SELECT DATE(created_at) as date, COUNT(*) as count
            FROM mlops.job_postings
            GROUP BY DATE(created_at)
            ORDER BY date DESC
            LIMIT 10
        '''))
        
        dates = result.fetchall()
        print(f'\nìµœê·¼ ìˆ˜ì§‘ ì¼ì (ìƒìœ„ 10ì¼):')
        for d in dates:
            print(f'  - {d.date}: {d.count}ê±´')
        
        # íšŒì‚¬ë³„ ê³µê³  ìˆ˜
        result = conn.execute(text('''
            SELECT company, COUNT(*) as count
            FROM mlops.job_postings
            GROUP BY company
            ORDER BY count DESC
            LIMIT 10
        '''))
        
        companies = result.fetchall()
        print(f'\nê³µê³ ê°€ ë§ì€ íšŒì‚¬ (ìƒìœ„ 10ê°œ):')
        for c in companies:
            print(f'  - {c.company}: {c.count}ê±´')
        
        return row.total


def check_cover_letters_quality():
    """ìê¸°ì†Œê°œì„œ ë°ì´í„° í’ˆì§ˆ ì ê²€"""
    engine = create_engine(DATABASE_URL)
    
    print("\n" + "=" * 80)
    print("ğŸ“Š ìê¸°ì†Œê°œì„œ ë°ì´í„° í’ˆì§ˆ ì ê²€")
    print("=" * 80)
    
    with engine.connect() as conn:
        # ì „ì²´ í†µê³„
        result = conn.execute(text('''
            SELECT 
                COUNT(*) as total,
                COUNT(DISTINCT company) as unique_companies,
                COUNT(DISTINCT url) as unique_urls,
                COUNT(CASE WHEN title IS NULL OR title = '' THEN 1 END) as missing_title,
                COUNT(CASE WHEN company IS NULL OR company = '' THEN 1 END) as missing_company,
                COUNT(CASE WHEN content IS NULL OR content = '' THEN 1 END) as missing_content,
                COUNT(CASE WHEN position IS NULL OR position = '' THEN 1 END) as missing_position,
                COUNT(CASE WHEN is_passed = true THEN 1 END) as passed_count,
                AVG(LENGTH(content)) as avg_content_length,
                MIN(LENGTH(content)) as min_content_length,
                MAX(LENGTH(content)) as max_content_length
            FROM mlops.cover_letter_samples
        '''))
        
        row = result.fetchone()
        print(f'\nê¸°ë³¸ í†µê³„:')
        print(f'  ì „ì²´ ë°ì´í„°: {row.total}ê±´')
        print(f'  ê³ ìœ  íšŒì‚¬: {row.unique_companies}ê°œ')
        print(f'  ê³ ìœ  URL: {row.unique_urls}ê°œ')
        print(f'  ì¤‘ë³µë¥ : {(row.total - row.unique_urls) / row.total * 100:.1f}%')
        print(f'  í•©ê²© ìì†Œì„œ: {row.passed_count}ê±´ ({row.passed_count/row.total*100:.1f}%)')
        
        print(f'\nê²°ì¸¡ì¹˜:')
        print(f'  - ì œëª© ëˆ„ë½: {row.missing_title}ê±´ ({row.missing_title/row.total*100:.1f}%)')
        print(f'  - íšŒì‚¬ëª… ëˆ„ë½: {row.missing_company}ê±´ ({row.missing_company/row.total*100:.1f}%)')
        print(f'  - ë‚´ìš© ëˆ„ë½: {row.missing_content}ê±´ ({row.missing_content/row.total*100:.1f}%)')
        print(f'  - ì§ë¬´ ëˆ„ë½: {row.missing_position}ê±´ ({row.missing_position/row.total*100:.1f}%)')
        
        print(f'\në‚´ìš© ê¸¸ì´ í†µê³„:')
        print(f'  - í‰ê· : {row.avg_content_length:.0f}ì')
        print(f'  - ìµœì†Œ: {row.min_content_length}ì')
        print(f'  - ìµœëŒ€: {row.max_content_length}ì')
        
        # ì¤‘ë³µ URL í™•ì¸
        result = conn.execute(text('''
            SELECT url, COUNT(*) as count, array_agg(id) as ids
            FROM mlops.cover_letter_samples
            WHERE url IS NOT NULL AND url != ''
            GROUP BY url
            HAVING COUNT(*) > 1
            ORDER BY count DESC
            LIMIT 10
        '''))
        
        duplicates = result.fetchall()
        print(f'\nì¤‘ë³µ URL: {len(duplicates)}ê°œ')
        if duplicates:
            print('  ìƒìœ„ 10ê°œ:')
            for dup in duplicates:
                print(f'    - {dup.url[:70]}... ({dup.count}ê±´)')
                print(f'      IDs: {dup.ids}')
        
        # ë¹„ì •ìƒì ìœ¼ë¡œ ì§§ì€ ë‚´ìš©
        result = conn.execute(text('''
            SELECT id, title, company, position, LENGTH(content) as content_len
            FROM mlops.cover_letter_samples
            WHERE LENGTH(content) < 200
            ORDER BY content_len
            LIMIT 10
        '''))
        
        short_content = result.fetchall()
        print(f'\në¹„ì •ìƒì ìœ¼ë¡œ ì§§ì€ ë‚´ìš© (< 200ì): {len(short_content)}ê±´')
        if short_content:
            for sc in short_content:
                print(f'    - ID {sc.id}: {sc.company} - {sc.position} ({sc.content_len}ì)')
        
        # íšŒì‚¬ë³„ ìì†Œì„œ ìˆ˜
        result = conn.execute(text('''
            SELECT company, COUNT(*) as count
            FROM mlops.cover_letter_samples
            GROUP BY company
            ORDER BY count DESC
            LIMIT 10
        '''))
        
        companies = result.fetchall()
        print(f'\nìì†Œì„œê°€ ë§ì€ íšŒì‚¬ (ìƒìœ„ 10ê°œ):')
        for c in companies:
            print(f'  - {c.company}: {c.count}ê±´')
        
        # ì§ë¬´ë³„ ìì†Œì„œ ìˆ˜
        result = conn.execute(text('''
            SELECT position, COUNT(*) as count
            FROM mlops.cover_letter_samples
            WHERE position IS NOT NULL AND position != ''
            GROUP BY position
            ORDER BY count DESC
            LIMIT 10
        '''))
        
        positions = result.fetchall()
        print(f'\nìì†Œì„œê°€ ë§ì€ ì§ë¬´ (ìƒìœ„ 10ê°œ):')
        for p in positions:
            print(f'  - {p.position}: {p.count}ê±´')
        
        return row.total


def clean_job_postings():
    """ì±„ìš©ê³µê³  ë°ì´í„° ì •ì œ"""
    engine = create_engine(DATABASE_URL)
    
    print("\n" + "=" * 80)
    print("ğŸ§¹ ì±„ìš©ê³µê³  ë°ì´í„° ì •ì œ")
    print("=" * 80)
    
    with engine.begin() as conn:
        # 1. ì¤‘ë³µ URL ì œê±° (ìµœì‹  ë°ì´í„°ë§Œ ìœ ì§€)
        result = conn.execute(text('''
            WITH duplicates AS (
                SELECT id, source_url,
                       ROW_NUMBER() OVER (PARTITION BY source_url ORDER BY created_at DESC, id DESC) as rn
                FROM mlops.job_postings
                WHERE source_url IS NOT NULL AND source_url != ''
            )
            DELETE FROM mlops.job_postings
            WHERE id IN (SELECT id FROM duplicates WHERE rn > 1)
            RETURNING id
        '''))
        
        deleted_count = len(result.fetchall())
        print(f'\nâœ“ ì¤‘ë³µ URL ì œê±°: {deleted_count}ê±´')
        
        # 2. ë¹„ì •ìƒì ìœ¼ë¡œ ì§§ì€ ì„¤ëª… ì œê±° (< 50ì)
        result = conn.execute(text('''
            DELETE FROM mlops.job_postings
            WHERE LENGTH(description) < 50
            RETURNING id
        '''))
        
        short_deleted = len(result.fetchall())
        print(f'âœ“ ë¹„ì •ìƒì ìœ¼ë¡œ ì§§ì€ ì„¤ëª… ì œê±° (< 50ì): {short_deleted}ê±´')
        
        # 3. ì œëª© ì •ê·œí™” (ì•ë’¤ ê³µë°± ì œê±°)
        result = conn.execute(text('''
            UPDATE mlops.job_postings
            SET title = TRIM(title),
                company = TRIM(company),
                location = TRIM(location)
            WHERE title != TRIM(title) 
               OR company != TRIM(company)
               OR (location IS NOT NULL AND location != TRIM(location))
            RETURNING id
        '''))
        
        trimmed_count = len(result.fetchall())
        print(f'âœ“ ê³µë°± ì •ê·œí™”: {trimmed_count}ê±´')
        
        # 4. NULL ë¬¸ìì—´ì„ ì‹¤ì œ NULLë¡œ ë³€í™˜
        result = conn.execute(text('''
            UPDATE mlops.job_postings
            SET location = NULL
            WHERE location = '' OR location = 'null' OR location = 'None'
            RETURNING id
        '''))
        
        null_fixed = len(result.fetchall())
        print(f'âœ“ NULL ë¬¸ìì—´ ì •ê·œí™”: {null_fixed}ê±´')
        
        # ìµœì¢… í†µê³„
        result = conn.execute(text('''
            SELECT COUNT(*) as total,
                   COUNT(DISTINCT company) as companies,
                   COUNT(DISTINCT source_url) as unique_urls
            FROM mlops.job_postings
        '''))
        
        row = result.fetchone()
        print(f'\nì •ì œ í›„ ë°ì´í„°:')
        print(f'  - ì´ {row.total}ê±´')
        print(f'  - {row.companies}ê°œ íšŒì‚¬')
        print(f'  - {row.unique_urls}ê°œ ê³ ìœ  URL')


def clean_cover_letters():
    """ìê¸°ì†Œê°œì„œ ë°ì´í„° ì •ì œ"""
    engine = create_engine(DATABASE_URL)
    
    print("\n" + "=" * 80)
    print("ğŸ§¹ ìê¸°ì†Œê°œì„œ ë°ì´í„° ì •ì œ")
    print("=" * 80)
    
    with engine.begin() as conn:
        # 1. ì¤‘ë³µ URL ì œê±° (ìµœì‹  ë°ì´í„°ë§Œ ìœ ì§€)
        result = conn.execute(text('''
            WITH duplicates AS (
                SELECT id, url,
                       ROW_NUMBER() OVER (PARTITION BY url ORDER BY created_at DESC, id DESC) as rn
                FROM mlops.cover_letter_samples
                WHERE url IS NOT NULL AND url != ''
            )
            DELETE FROM mlops.cover_letter_samples
            WHERE id IN (SELECT id FROM duplicates WHERE rn > 1)
            RETURNING id
        '''))
        
        deleted_count = len(result.fetchall())
        print(f'\nâœ“ ì¤‘ë³µ URL ì œê±°: {deleted_count}ê±´')
        
        # 2. ë¹„ì •ìƒì ìœ¼ë¡œ ì§§ì€ ë‚´ìš© ì œê±° (< 100ì)
        result = conn.execute(text('''
            DELETE FROM mlops.cover_letter_samples
            WHERE LENGTH(content) < 100
            RETURNING id
        '''))
        
        short_deleted = len(result.fetchall())
        print(f'âœ“ ë¹„ì •ìƒì ìœ¼ë¡œ ì§§ì€ ë‚´ìš© ì œê±° (< 100ì): {short_deleted}ê±´')
        
        # 3. í…ìŠ¤íŠ¸ ì •ê·œí™” (ì•ë’¤ ê³µë°± ì œê±°)
        result = conn.execute(text('''
            UPDATE mlops.cover_letter_samples
            SET title = TRIM(title),
                company = TRIM(company),
                position = TRIM(position),
                content = TRIM(content)
            WHERE title != TRIM(title) 
               OR company != TRIM(company)
               OR (position IS NOT NULL AND position != TRIM(position))
               OR content != TRIM(content)
            RETURNING id
        '''))
        
        trimmed_count = len(result.fetchall())
        print(f'âœ“ ê³µë°± ì •ê·œí™”: {trimmed_count}ê±´')
        
        # 4. NULL ë¬¸ìì—´ì„ ì‹¤ì œ NULLë¡œ ë³€í™˜
        result = conn.execute(text('''
            UPDATE mlops.cover_letter_samples
            SET position = NULL,
                department = NULL,
                experience_level = NULL
            WHERE (position = '' OR position = 'null' OR position = 'None')
               OR (department = '' OR department = 'null' OR department = 'None')
               OR (experience_level = '' OR experience_level = 'null' OR experience_level = 'None')
            RETURNING id
        '''))
        
        null_fixed = len(result.fetchall())
        print(f'âœ“ NULL ë¬¸ìì—´ ì •ê·œí™”: {null_fixed}ê±´')
        
        # ìµœì¢… í†µê³„
        result = conn.execute(text('''
            SELECT COUNT(*) as total,
                   COUNT(DISTINCT company) as companies,
                   COUNT(DISTINCT url) as unique_urls,
                   COUNT(CASE WHEN is_passed = true THEN 1 END) as passed
            FROM mlops.cover_letter_samples
        '''))
        
        row = result.fetchone()
        print(f'\nì •ì œ í›„ ë°ì´í„°:')
        print(f'  - ì´ {row.total}ê±´')
        print(f'  - {row.companies}ê°œ íšŒì‚¬')
        print(f'  - {row.unique_urls}ê°œ ê³ ìœ  URL')
        print(f'  - {row.passed}ê±´ í•©ê²© ìì†Œì„œ')


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 80)
    print(f"ğŸ” ë°ì´í„° í’ˆì§ˆ ì ê²€ ë° ì •ì œ ì‹œì‘: {datetime.now()}")
    print("=" * 80)
    
    # 1. í’ˆì§ˆ ì ê²€
    jp_count = check_job_postings_quality()
    cl_count = check_cover_letters_quality()
    
    # 2. ë°ì´í„° ì •ì œ í™•ì¸
    print("\n" + "=" * 80)
    print("ë°ì´í„° ì •ì œë¥¼ ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ?")
    print("=" * 80)
    print(f"ì±„ìš©ê³µê³ : {jp_count}ê±´")
    print(f"ìê¸°ì†Œê°œì„œ: {cl_count}ê±´")
    print("\nì •ì œ ì‘ì—…:")
    print("  - ì¤‘ë³µ ë°ì´í„° ì œê±°")
    print("  - ë¹„ì •ìƒì ìœ¼ë¡œ ì§§ì€ ë°ì´í„° ì œê±°")
    print("  - í…ìŠ¤íŠ¸ ì •ê·œí™” (ê³µë°± ì œê±°)")
    print("  - NULL ê°’ ì •ê·œí™”")
    
    # ìë™ ì‹¤í–‰ (ìŠ¤í¬ë¦½íŠ¸ ëª¨ë“œ)
    response = 'y'
    
    if response.lower() == 'y':
        # 3. ë°ì´í„° ì •ì œ
        clean_job_postings()
        clean_cover_letters()
        
        print("\n" + "=" * 80)
        print(f"âœ… ë°ì´í„° í’ˆì§ˆ ì ê²€ ë° ì •ì œ ì™„ë£Œ: {datetime.now()}")
        print("=" * 80)
    else:
        print("\nì •ì œ ì‘ì—…ì„ ê±´ë„ˆëœë‹ˆë‹¤.")


if __name__ == "__main__":
    main()
