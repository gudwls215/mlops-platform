#!/usr/bin/env python3
"""
Linkareer ìê¸°ì†Œê°œì„œ í¬ë¡¤ëŸ¬ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
ëª©í‘œ: 1,000ê±´ì˜ ìê¸°ì†Œê°œì„œ ìˆ˜ì§‘
"""
import sys
import os
from datetime import datetime

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€
project_path = '/home/ttm/tensorflow-jupyter/jupyterNotebook/khj/mlops-platform'
sys.path.insert(0, project_path)
sys.path.insert(0, os.path.join(project_path, 'crawling'))
sys.path.insert(0, os.path.join(project_path, 'crawling', 'scrapers'))

from scrapers.linkareer_crawler import LinkareerCoverLetterCrawler
from sqlalchemy import create_engine, text
from dotenv import load_dotenv

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
DATABASE_URL = os.getenv("DATABASE_URL")


def check_current_status():
    """í˜„ì¬ ìˆ˜ì§‘ ìƒíƒœ í™•ì¸"""
    engine = create_engine(DATABASE_URL)
    
    with engine.connect() as conn:
        result = conn.execute(text("""
            SELECT COUNT(*) as total,
                   COUNT(DISTINCT company) as companies,
                   COUNT(CASE WHEN is_passed = true THEN 1 END) as passed
            FROM mlops.cover_letter_samples
        """))
        
        row = result.fetchone()
        
        print("\n" + "=" * 80)
        print("ğŸ“Š ìê¸°ì†Œê°œì„œ í˜„ì¬ ìˆ˜ì§‘ í˜„í™©")
        print("=" * 80)
        print(f"  ì´ ìê¸°ì†Œê°œì„œ: {row.total}ê±´")
        print(f"  ê³ ìœ  íšŒì‚¬: {row.companies}ê°œ")
        print(f"  í•©ê²© ìì†Œì„œ: {row.passed}ê±´")
        print(f"  ëª©í‘œ ëŒ€ë¹„: {row.total / 1000 * 100:.1f}% (ëª©í‘œ 1,000ê±´)")
        print("=" * 80 + "\n")
        
        return row.total


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 80)
    print(f"ğŸš€ Linkareer ìê¸°ì†Œê°œì„œ í¬ë¡¤ë§ ì‹œì‘: {datetime.now()}")
    print("=" * 80)
    
    # í˜„ì¬ ìƒíƒœ í™•ì¸
    current_count = check_current_status()
    
    # ëª©í‘œ ê°œìˆ˜ ê³„ì‚°
    target = 1000
    needed = max(target - current_count, 0)
    
    if needed == 0:
        print(f"âœ… ì´ë¯¸ ëª©í‘œ({target}ê±´)ë¥¼ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤!")
        return
    
    print(f"ğŸ“‹ ì¶”ê°€ë¡œ ìˆ˜ì§‘í•  ê°œìˆ˜: {needed}ê±´\n")
    
    # í¬ë¡¤ëŸ¬ ì‹¤í–‰
    crawler = LinkareerCoverLetterCrawler()
    
    try:
        print(f"â³ í¬ë¡¤ë§ ì‹œì‘... (ëª©í‘œ: {needed}ê±´)")
        result = crawler.crawl(max_items=needed)
        
        print("\n" + "=" * 80)
        print(f"âœ… í¬ë¡¤ë§ ì™„ë£Œ: {datetime.now()}")
        print("=" * 80)
        print(f"  ê²°ê³¼: {result}")
        print("=" * 80)
        
        # ìµœì¢… ìƒíƒœ í™•ì¸
        print("\nìµœì¢… ìˆ˜ì§‘ í˜„í™©:")
        check_current_status()
        
    except Exception as e:
        print(f"\nâŒ í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        raise


if __name__ == "__main__":
    main()
