"""
ì´ë ¥ì„œ ìƒì„± API ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

í…ìŠ¤íŠ¸ ì…ë ¥ìœ¼ë¡œ ì´ë ¥ì„œë¥¼ ìƒì„±í•˜ëŠ” APIì˜ ì„±ëŠ¥ì„ ì¸¡ì •í•©ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    python test_resume_generation_performance.py [--api-url URL] [--iterations N]
"""
import asyncio
import aiohttp
import time
import statistics
import argparse
import os
import sys
from typing import List, Dict, Any, Optional
from dataclasses import dataclass, field
from datetime import datetime
import json
import random
import string


@dataclass
class PerformanceResult:
    """ì„±ëŠ¥ ì¸¡ì • ê²°ê³¼"""
    iteration: int
    duration_ms: float
    status_code: int
    success: bool
    resume_id: Optional[int] = None
    error_message: str = ""


@dataclass
class PerformanceReport:
    """ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ë¦¬í¬íŠ¸"""
    test_name: str
    total_iterations: int
    successful_iterations: int
    failed_iterations: int
    total_duration_ms: float
    avg_duration_ms: float
    min_duration_ms: float
    max_duration_ms: float
    p50_duration_ms: float
    p95_duration_ms: float
    p99_duration_ms: float
    std_dev_ms: float
    throughput_per_sec: float
    results: List[PerformanceResult] = field(default_factory=list)
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "test_name": self.test_name,
            "total_iterations": self.total_iterations,
            "successful_iterations": self.successful_iterations,
            "failed_iterations": self.failed_iterations,
            "total_duration_ms": round(self.total_duration_ms, 2),
            "avg_duration_ms": round(self.avg_duration_ms, 2),
            "min_duration_ms": round(self.min_duration_ms, 2),
            "max_duration_ms": round(self.max_duration_ms, 2),
            "p50_duration_ms": round(self.p50_duration_ms, 2),
            "p95_duration_ms": round(self.p95_duration_ms, 2),
            "p99_duration_ms": round(self.p99_duration_ms, 2),
            "std_dev_ms": round(self.std_dev_ms, 2),
            "throughput_per_sec": round(self.throughput_per_sec, 4),
            "success_rate": round(self.successful_iterations / self.total_iterations * 100, 2)
        }


def calculate_percentile(data: List[float], percentile: float) -> float:
    """í¼ì„¼íƒ€ì¼ ê³„ì‚°"""
    if not data:
        return 0.0
    sorted_data = sorted(data)
    index = (len(sorted_data) - 1) * percentile / 100
    lower = int(index)
    upper = lower + 1
    if upper >= len(sorted_data):
        return sorted_data[-1]
    weight = index - lower
    return sorted_data[lower] * (1 - weight) + sorted_data[upper] * weight


# ìƒ˜í”Œ ì´ë ¥ì„œ ë°ì´í„° í…œí”Œë¦¿
SAMPLE_RESUME_TEMPLATES = [
    {
        "title": "ë°±ì—”ë“œ ê°œë°œì ì´ë ¥ì„œ",
        "content": """ì•ˆë…•í•˜ì„¸ìš”. ì €ëŠ” 5ë…„ì°¨ ë°±ì—”ë“œ ê°œë°œìì…ë‹ˆë‹¤.

ê²½ë ¥ì‚¬í•­:
- 2020.03 ~ í˜„ì¬: ABC í…Œí¬ - ì‹œë‹ˆì–´ ë°±ì—”ë“œ ê°œë°œì
  - Python/FastAPI ê¸°ë°˜ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ê°œë°œ
  - PostgreSQL, Redis í™œìš©í•œ ë°ì´í„° ì²˜ë¦¬ ì‹œìŠ¤í…œ êµ¬ì¶•
  - ì¼ 100ë§Œ íŠ¸ëœì­ì…˜ ì²˜ë¦¬ ì‹œìŠ¤í…œ ìš´ì˜

- 2018.01 ~ 2020.02: XYZ ì†Œí”„íŠ¸ - ì£¼ë‹ˆì–´ ê°œë°œì
  - Django ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œ
  - RESTful API ì„¤ê³„ ë° êµ¬í˜„

í•™ë ¥:
- 2018: OOëŒ€í•™êµ ì»´í“¨í„°ê³µí•™ê³¼ ì¡¸ì—…

ê¸°ìˆ  ìŠ¤íƒ:
Python, FastAPI, Django, PostgreSQL, Redis, Docker, Kubernetes, AWS""",
        "skills": ["Python", "FastAPI", "Django", "PostgreSQL", "Redis", "Docker", "Kubernetes", "AWS"]
    },
    {
        "title": "í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œì ì´ë ¥ì„œ",
        "content": """ì €ëŠ” 4ë…„ì°¨ í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œìì…ë‹ˆë‹¤.

ê²½ë ¥ì‚¬í•­:
- 2021.06 ~ í˜„ì¬: DEF ìŠ¤íƒ€íŠ¸ì—… - í”„ë¡ íŠ¸ì—”ë“œ ë¦¬ë“œ
  - React/TypeScript ê¸°ë°˜ SPA ê°œë°œ
  - ë””ìì¸ ì‹œìŠ¤í…œ êµ¬ì¶• ë° ì»´í¬ë„ŒíŠ¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ê°œë°œ
  - ì›¹ ì„±ëŠ¥ ìµœì í™” (LCP 2ì´ˆ ì´í•˜ ë‹¬ì„±)

- 2019.03 ~ 2021.05: GHI ì»´í¼ë‹ˆ - í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œì
  - Vue.js ê¸°ë°˜ ê´€ë¦¬ì ëŒ€ì‹œë³´ë“œ ê°œë°œ
  - ë°˜ì‘í˜• ì›¹ ë””ìì¸ êµ¬í˜„

í•™ë ¥:
- 2019: XXëŒ€í•™êµ ì†Œí”„íŠ¸ì›¨ì–´í•™ê³¼ ì¡¸ì—…

ê¸°ìˆ  ìŠ¤íƒ:
React, TypeScript, Vue.js, Next.js, Tailwind CSS, Webpack, Jest""",
        "skills": ["React", "TypeScript", "Vue.js", "Next.js", "Tailwind CSS", "Webpack", "Jest"]
    },
    {
        "title": "ë°ì´í„° ì—”ì§€ë‹ˆì–´ ì´ë ¥ì„œ",
        "content": """ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ê²½ë ¥ì‚¬í•­:
- 2019.09 ~ í˜„ì¬: JKL ë°ì´í„° - ì‹œë‹ˆì–´ ë°ì´í„° ì—”ì§€ë‹ˆì–´
  - Apache Spark ê¸°ë°˜ ëŒ€ìš©ëŸ‰ ë°ì´í„° íŒŒì´í”„ë¼ì¸ êµ¬ì¶•
  - Airflowë¥¼ í™œìš©í•œ ETL ì›Œí¬í”Œë¡œìš° ìë™í™”
  - ë°ì´í„° ë ˆì´í¬ ì•„í‚¤í…ì²˜ ì„¤ê³„

- 2017.07 ~ 2019.08: MNO ë¶„ì„ - ë°ì´í„° ë¶„ì„ê°€
  - SQL ê¸°ë°˜ ë¹„ì¦ˆë‹ˆìŠ¤ ë°ì´í„° ë¶„ì„
  - Tableau ëŒ€ì‹œë³´ë“œ ê°œë°œ

í•™ë ¥:
- 2017: YYëŒ€í•™êµ í†µê³„í•™ê³¼ ì¡¸ì—…
- 2019: ZZëŒ€í•™ì› ë¹…ë°ì´í„° ì„ì‚¬

ê¸°ìˆ  ìŠ¤íƒ:
Python, Spark, Airflow, Kafka, Hadoop, SQL, Tableau, AWS Glue""",
        "skills": ["Python", "Spark", "Airflow", "Kafka", "Hadoop", "SQL", "Tableau", "AWS"]
    }
]


def generate_random_resume_data(iteration: int) -> Dict[str, Any]:
    """ëœë¤ ì´ë ¥ì„œ ë°ì´í„° ìƒì„±"""
    template = random.choice(SAMPLE_RESUME_TEMPLATES)
    
    # ê³ ìœ ì„±ì„ ìœ„í•´ ëœë¤ ë¬¸ìì—´ ì¶”ê°€
    random_suffix = ''.join(random.choices(string.ascii_letters + string.digits, k=8))
    
    return {
        "title": f"{template['title']} - {iteration}_{random_suffix}",
        "content": template["content"],
        "skills": json.dumps(template["skills"])
    }


async def test_resume_creation_api(
    session: aiohttp.ClientSession,
    api_url: str,
    iteration: int,
    user_id: int = 1
) -> PerformanceResult:
    """ì´ë ¥ì„œ ìƒì„± API ë‹¨ì¼ ìš”ì²­ í…ŒìŠ¤íŠ¸"""
    
    start_time = time.perf_counter()
    
    try:
        resume_data = generate_random_resume_data(iteration)
        
        # FormData ìƒì„±
        data = aiohttp.FormData()
        data.add_field('title', resume_data["title"])
        data.add_field('content', resume_data["content"])
        data.add_field('skills', resume_data["skills"])
        data.add_field('user_id', str(user_id))
        
        async with session.post(f"{api_url}/api/resumes/", data=data) as response:
            end_time = time.perf_counter()
            duration_ms = (end_time - start_time) * 1000
            
            response_json = await response.json()
            
            if response.status == 200 and response_json.get("status") == "success":
                resume_id = response_json.get("data", {}).get("id")
                return PerformanceResult(
                    iteration=iteration,
                    duration_ms=duration_ms,
                    status_code=response.status,
                    success=True,
                    resume_id=resume_id
                )
            else:
                return PerformanceResult(
                    iteration=iteration,
                    duration_ms=duration_ms,
                    status_code=response.status,
                    success=False,
                    error_message=response_json.get("error", str(response_json))
                )
    
    except Exception as e:
        end_time = time.perf_counter()
        duration_ms = (end_time - start_time) * 1000
        return PerformanceResult(
            iteration=iteration,
            duration_ms=duration_ms,
            status_code=0,
            success=False,
            error_message=str(e)
        )


async def test_resume_fetch_api(
    session: aiohttp.ClientSession,
    api_url: str,
    resume_id: int,
    iteration: int
) -> PerformanceResult:
    """ì´ë ¥ì„œ ì¡°íšŒ API í…ŒìŠ¤íŠ¸"""
    
    start_time = time.perf_counter()
    
    try:
        async with session.get(f"{api_url}/api/resumes/{resume_id}") as response:
            end_time = time.perf_counter()
            duration_ms = (end_time - start_time) * 1000
            
            response_json = await response.json()
            
            if response.status == 200 and response_json.get("status") == "success":
                return PerformanceResult(
                    iteration=iteration,
                    duration_ms=duration_ms,
                    status_code=response.status,
                    success=True,
                    resume_id=resume_id
                )
            else:
                return PerformanceResult(
                    iteration=iteration,
                    duration_ms=duration_ms,
                    status_code=response.status,
                    success=False,
                    error_message=response_json.get("error", "Unknown error")
                )
    
    except Exception as e:
        end_time = time.perf_counter()
        duration_ms = (end_time - start_time) * 1000
        return PerformanceResult(
            iteration=iteration,
            duration_ms=duration_ms,
            status_code=0,
            success=False,
            error_message=str(e)
        )


async def run_resume_creation_test(
    api_url: str,
    iterations: int,
    concurrency: int = 1
) -> PerformanceReport:
    """ì´ë ¥ì„œ ìƒì„± í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    
    test_type = "ë™ì‹œ ì‹¤í–‰" if concurrency > 1 else "ìˆœì°¨ ì‹¤í–‰"
    
    print(f"\n{'='*60}")
    print(f"ì´ë ¥ì„œ ìƒì„± API ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ({test_type})")
    print(f"{'='*60}")
    print(f"API URL: {api_url}")
    print(f"ë°˜ë³µ íšŸìˆ˜: {iterations}")
    if concurrency > 1:
        print(f"ë™ì‹œ ì‹¤í–‰ ìˆ˜: {concurrency}")
    print(f"{'='*60}\n")
    
    results: List[PerformanceResult] = []
    
    timeout = aiohttp.ClientTimeout(total=120)
    connector = aiohttp.TCPConnector(limit=concurrency)
    
    async with aiohttp.ClientSession(timeout=timeout, connector=connector) as session:
        if concurrency > 1:
            # ë™ì‹œ ì‹¤í–‰
            semaphore = asyncio.Semaphore(concurrency)
            
            async def bounded_test(iteration: int):
                async with semaphore:
                    return await test_resume_creation_api(session, api_url, iteration)
            
            tasks = [bounded_test(i) for i in range(1, iterations + 1)]
            
            print(f"ì´ {len(tasks)}ê°œ ìš”ì²­ ì‹œì‘...")
            results = list(await asyncio.gather(*tasks))
        else:
            # ìˆœì°¨ ì‹¤í–‰
            for i in range(1, iterations + 1):
                print(f"[{i}/{iterations}] í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘...", end=" ")
                result = await test_resume_creation_api(session, api_url, i)
                results.append(result)
                
                if result.success:
                    print(f"âœ“ {result.duration_ms:.2f}ms (ì´ë ¥ì„œ ID: {result.resume_id})")
                else:
                    print(f"âœ— ì‹¤íŒ¨: {result.error_message}")
    
    return generate_report(f"ì´ë ¥ì„œ ìƒì„± API í…ŒìŠ¤íŠ¸ ({test_type})", results)


async def run_resume_fetch_test(
    api_url: str,
    iterations: int,
    resume_ids: List[int] = None,
    concurrency: int = 1
) -> PerformanceReport:
    """ì´ë ¥ì„œ ì¡°íšŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    
    test_type = "ë™ì‹œ ì‹¤í–‰" if concurrency > 1 else "ìˆœì°¨ ì‹¤í–‰"
    
    print(f"\n{'='*60}")
    print(f"ì´ë ¥ì„œ ì¡°íšŒ API ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ({test_type})")
    print(f"{'='*60}")
    print(f"API URL: {api_url}")
    print(f"ë°˜ë³µ íšŸìˆ˜: {iterations}")
    print(f"{'='*60}\n")
    
    # ì´ë ¥ì„œ ëª©ë¡ ì¡°íšŒ
    if not resume_ids:
        async with aiohttp.ClientSession() as session:
            async with session.get(f"{api_url}/api/resumes/?limit=100") as response:
                data = await response.json()
                if data.get("status") == "success":
                    resume_ids = [r["id"] for r in data.get("data", {}).get("resumes", [])]
                    if not resume_ids:
                        print("âŒ ì¡°íšŒí•  ì´ë ¥ì„œê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì´ë ¥ì„œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.")
                        return None
    
    print(f"ì¡°íšŒí•  ì´ë ¥ì„œ ìˆ˜: {len(resume_ids)}")
    
    results: List[PerformanceResult] = []
    
    timeout = aiohttp.ClientTimeout(total=60)
    connector = aiohttp.TCPConnector(limit=concurrency)
    
    async with aiohttp.ClientSession(timeout=timeout, connector=connector) as session:
        for i in range(1, iterations + 1):
            resume_id = random.choice(resume_ids)
            print(f"[{i}/{iterations}] ì´ë ¥ì„œ {resume_id} ì¡°íšŒ ì¤‘...", end=" ")
            result = await test_resume_fetch_api(session, api_url, resume_id, i)
            results.append(result)
            
            if result.success:
                print(f"âœ“ {result.duration_ms:.2f}ms")
            else:
                print(f"âœ— ì‹¤íŒ¨: {result.error_message}")
    
    return generate_report(f"ì´ë ¥ì„œ ì¡°íšŒ API í…ŒìŠ¤íŠ¸ ({test_type})", results)


def generate_report(test_name: str, results: List[PerformanceResult]) -> PerformanceReport:
    """ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„±"""
    
    successful = [r for r in results if r.success]
    failed = [r for r in results if not r.success]
    
    if not successful:
        return PerformanceReport(
            test_name=test_name,
            total_iterations=len(results),
            successful_iterations=0,
            failed_iterations=len(results),
            total_duration_ms=0,
            avg_duration_ms=0,
            min_duration_ms=0,
            max_duration_ms=0,
            p50_duration_ms=0,
            p95_duration_ms=0,
            p99_duration_ms=0,
            std_dev_ms=0,
            throughput_per_sec=0,
            results=results
        )
    
    durations = [r.duration_ms for r in successful]
    total_duration = sum(durations)
    
    return PerformanceReport(
        test_name=test_name,
        total_iterations=len(results),
        successful_iterations=len(successful),
        failed_iterations=len(failed),
        total_duration_ms=total_duration,
        avg_duration_ms=statistics.mean(durations),
        min_duration_ms=min(durations),
        max_duration_ms=max(durations),
        p50_duration_ms=calculate_percentile(durations, 50),
        p95_duration_ms=calculate_percentile(durations, 95),
        p99_duration_ms=calculate_percentile(durations, 99),
        std_dev_ms=statistics.stdev(durations) if len(durations) > 1 else 0,
        throughput_per_sec=len(successful) / (total_duration / 1000) if total_duration > 0 else 0,
        results=results
    )


def print_report(report: PerformanceReport):
    """ë¦¬í¬íŠ¸ ì¶œë ¥"""
    
    if report is None:
        return
    
    print(f"\n{'='*60}")
    print(f"ğŸ“Š {report.test_name} ê²°ê³¼")
    print(f"{'='*60}")
    print(f"ì´ ìš”ì²­ ìˆ˜: {report.total_iterations}")
    print(f"ì„±ê³µ: {report.successful_iterations} ({report.successful_iterations/report.total_iterations*100:.1f}%)")
    print(f"ì‹¤íŒ¨: {report.failed_iterations}")
    print(f"\nâ±ï¸  ì‘ë‹µ ì‹œê°„ í†µê³„ (ms):")
    print(f"  - í‰ê· : {report.avg_duration_ms:.2f}")
    print(f"  - ìµœì†Œ: {report.min_duration_ms:.2f}")
    print(f"  - ìµœëŒ€: {report.max_duration_ms:.2f}")
    print(f"  - P50: {report.p50_duration_ms:.2f}")
    print(f"  - P95: {report.p95_duration_ms:.2f}")
    print(f"  - P99: {report.p99_duration_ms:.2f}")
    print(f"  - í‘œì¤€í¸ì°¨: {report.std_dev_ms:.2f}")
    print(f"\nğŸš€ ì²˜ë¦¬ëŸ‰: {report.throughput_per_sec:.4f} req/sec")
    print(f"{'='*60}")


def save_report(report: PerformanceReport, output_path: str):
    """ë¦¬í¬íŠ¸ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
    if report is None:
        return
    
    report_data = report.to_dict()
    report_data["timestamp"] = datetime.now().isoformat()
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(report_data, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ“ ë¦¬í¬íŠ¸ ì €ì¥: {output_path}")


async def main():
    parser = argparse.ArgumentParser(description="ì´ë ¥ì„œ ìƒì„± API ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")
    parser.add_argument("--api-url", default="http://localhost:8000", help="API ì„œë²„ URL")
    parser.add_argument("--iterations", type=int, default=10, help="í…ŒìŠ¤íŠ¸ ë°˜ë³µ íšŸìˆ˜")
    parser.add_argument("--concurrent", type=int, default=1, help="ë™ì‹œ ì‹¤í–‰ ìˆ˜")
    parser.add_argument("--test-type", choices=["create", "fetch", "both"], default="both", 
                        help="í…ŒìŠ¤íŠ¸ ìœ í˜•: create(ìƒì„±), fetch(ì¡°íšŒ), both(ëª¨ë‘)")
    parser.add_argument("--output", type=str, help="ê²°ê³¼ ì €ì¥ íŒŒì¼ ê²½ë¡œ (JSON)")
    
    args = parser.parse_args()
    
    reports = []
    
    if args.test_type in ["create", "both"]:
        report = await run_resume_creation_test(
            args.api_url,
            args.iterations,
            args.concurrent
        )
        print_report(report)
        reports.append(("resume_creation", report))
    
    if args.test_type in ["fetch", "both"]:
        report = await run_resume_fetch_test(
            args.api_url,
            args.iterations,
            concurrency=args.concurrent
        )
        print_report(report)
        if report:
            reports.append(("resume_fetch", report))
    
    # ê²°ê³¼ ì €ì¥
    output_path = args.output or os.path.join(
        os.path.dirname(__file__),
        f"resume_performance_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    )
    
    combined_report = {
        "timestamp": datetime.now().isoformat(),
        "config": {
            "api_url": args.api_url,
            "iterations": args.iterations,
            "concurrent": args.concurrent,
            "test_type": args.test_type
        },
        "results": {name: report.to_dict() for name, report in reports if report}
    }
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(combined_report, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ“ ì¢…í•© ë¦¬í¬íŠ¸ ì €ì¥: {output_path}")


if __name__ == "__main__":
    asyncio.run(main())
