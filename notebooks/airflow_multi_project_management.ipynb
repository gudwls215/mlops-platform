{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "578914b7",
   "metadata": {},
   "source": [
    "# Airflow ë‹¤ì¤‘ í”„ë¡œì íŠ¸ ê´€ë¦¬ ê°€ì´ë“œ\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ movielens-mlopsì™€ mlops-platform ë‘ ê°œ í”„ë¡œì íŠ¸ì˜ DAGë¥¼ í•˜ë‚˜ì˜ Airflow ì¸ìŠ¤í„´ìŠ¤ë¡œ í†µí•© ê´€ë¦¬í•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤.\n",
    "\n",
    "## ğŸ¯ ëª©í‘œ\n",
    "- ë‹¨ì¼ Airflow ì¸ìŠ¤í„´ìŠ¤ë¡œ ì—¬ëŸ¬ í”„ë¡œì íŠ¸ ê´€ë¦¬\n",
    "- íŒŒì¼ ê²½ë¡œ ë¬¸ì œ í•´ê²°\n",
    "- DAG ì‹¤í–‰ í™˜ê²½ í†µí•©\n",
    "- íš¨ìœ¨ì ì¸ ì›Œí¬í”Œë¡œìš° ê´€ë¦¬\n",
    "\n",
    "## ğŸ“‹ í˜„ì¬ ìƒí™©\n",
    "- **movielens-mlops**: ê¸°ì¡´ ì‹¤í–‰ ì¤‘ì¸ Airflow (í¬íŠ¸ 8080)\n",
    "- **mlops-platform**: ìƒˆë¡œìš´ ë°ì´í„° ìˆ˜ì§‘ DAG\n",
    "- **ë¬¸ì œ**: íŒŒì¼ ê²½ë¡œ ë¶ˆì¼ì¹˜ë¡œ DAG ì‹¤í–‰ ì‹¤íŒ¨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea743adf",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Configuration\n",
    "\n",
    "ë¨¼ì € í˜„ì¬ í™˜ê²½ì„ ì ê²€í•˜ê³  í•„ìš”í•œ í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c5359b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# í˜„ì¬ í™˜ê²½ í™•ì¸\n",
    "print(\"=== í˜„ì¬ í™˜ê²½ ìƒíƒœ ===\")\n",
    "print(f\"í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬: {os.getcwd()}\")\n",
    "print(f\"AIRFLOW_HOME: {os.environ.get('AIRFLOW_HOME', 'Not set')}\")\n",
    "print(f\"PATH: {os.environ.get('PATH', 'Not set')[:100]}...\")\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ê²½ë¡œ ì •ì˜\n",
    "movielens_path = \"/home/ttm/tensorflow-jupyter/jupyterNotebook/khj/movielens-mlops\"\n",
    "mlops_platform_path = \"/home/ttm/tensorflow-jupyter/jupyterNotebook/khj/mlops-platform\"\n",
    "\n",
    "print(f\"\\n=== í”„ë¡œì íŠ¸ ê²½ë¡œ í™•ì¸ ===\")\n",
    "print(f\"Movielens-MLOps: {os.path.exists(movielens_path)} - {movielens_path}\")\n",
    "print(f\"MLOps-Platform: {os.path.exists(mlops_platform_path)} - {mlops_platform_path}\")\n",
    "\n",
    "# DAG í´ë” í™•ì¸\n",
    "dag_folders = [\n",
    "    \"/home/ttm/airflow/dags\",\n",
    "    \"/home/ttm/tensorflow-jupyter/jupyterNotebook/khj/movielens-mlops/airflow/dags\",\n",
    "    \"/home/ttm/tensorflow-jupyter/jupyterNotebook/khj/movielens-mlops/dags\"\n",
    "]\n",
    "\n",
    "print(f\"\\n=== DAG í´ë” í™•ì¸ ===\")\n",
    "for folder in dag_folders:\n",
    "    exists = os.path.exists(folder)\n",
    "    if exists:\n",
    "        files = os.listdir(folder)\n",
    "        dag_files = [f for f in files if f.endswith('.py')]\n",
    "        print(f\"âœ… {folder} - DAG files: {len(dag_files)}\")\n",
    "        for dag_file in dag_files[:3]:  # ì²˜ìŒ 3ê°œë§Œ í‘œì‹œ\n",
    "            print(f\"    - {dag_file}\")\n",
    "    else:\n",
    "        print(f\"âŒ {folder} - ì¡´ì¬í•˜ì§€ ì•ŠìŒ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80677fa",
   "metadata": {},
   "source": [
    "## 2. File Path Resolution and Debugging\n",
    "\n",
    "í˜„ì¬ DAG ì‹¤í–‰ ì‹¤íŒ¨ì˜ ì£¼ìš” ì›ì¸ì¸ íŒŒì¼ ê²½ë¡œ ë¬¸ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90873cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í¬ë¡¤ëŸ¬ íŒŒì¼ ê²½ë¡œ í™•ì¸ ë° ìƒì„±\n",
    "crawling_files = [\n",
    "    'saramin_crawler.py',\n",
    "    'linkareer_crawler.py',\n",
    "    'text_cleaner.py',\n",
    "    'duplicate_remover.py',\n",
    "    'batch_processor_manager.py',\n",
    "    'database.py'\n",
    "]\n",
    "\n",
    "mlops_crawling_path = '/home/ttm/tensorflow-jupyter/jupyterNotebook/khj/mlops-platform/crawling'\n",
    "\n",
    "print(\"=== MLOps-Platform í¬ë¡¤ë§ íŒŒì¼ í™•ì¸ ===\")\n",
    "for file in crawling_files:\n",
    "    file_path = os.path.join(mlops_crawling_path, file)\n",
    "    exists = os.path.exists(file_path)\n",
    "    status = \"âœ…\" if exists else \"âŒ\"\n",
    "    print(f\"{status} {file_path}\")\n",
    "    \n",
    "    if not exists:\n",
    "        print(f\"    âš ï¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {file}\")\n",
    "\n",
    "# í•„ìˆ˜ ë””ë ‰í† ë¦¬ í™•ì¸\n",
    "if not os.path.exists(mlops_crawling_path):\n",
    "    print(f\"\\nâŒ í¬ë¡¤ë§ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {mlops_crawling_path}\")\n",
    "    print(\"ğŸ“‹ í•´ê²° ë°©ë²•:\")\n",
    "    print(\"1. ë””ë ‰í† ë¦¬ ìƒì„±\")\n",
    "    print(\"2. í•„ìš”í•œ í¬ë¡¤ëŸ¬ íŒŒì¼ë“¤ ë³µì‚¬ ë˜ëŠ” ìƒì„±\")\n",
    "else:\n",
    "    print(f\"\\nâœ… í¬ë¡¤ë§ ë””ë ‰í† ë¦¬ ì¡´ì¬: {mlops_crawling_path}\")\n",
    "    \n",
    "# Python ëª¨ë“ˆ ê²½ë¡œ í™•ì¸\n",
    "print(f\"\\n=== Python ëª¨ë“ˆ ê²½ë¡œ ===\")\n",
    "import sys\n",
    "for i, path in enumerate(sys.path[:5]):  # ì²˜ìŒ 5ê°œë§Œ í‘œì‹œ\n",
    "    print(f\"{i+1}. {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3746425",
   "metadata": {},
   "source": [
    "## 3. í†µí•© Airflow ì„¤ì • ë°©ë²•\n",
    "\n",
    "### ë°©ë²• 1: ë‹¨ì¼ Airflowë¡œ í†µí•© ê´€ë¦¬ (ê¶Œì¥)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4f5a6e",
   "metadata": {
    "vscode": {
     "languageId": "bash"
    }
   },
   "outputs": [],
   "source": [
    "# 1ë‹¨ê³„: ê³µí†µ DAG í´ë” ì„¤ì •\n",
    "# í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ Airflowì˜ DAG í´ë” ì‚¬ìš©\n",
    "echo \"í˜„ì¬ Airflow DAG í´ë”: /home/ttm/tensorflow-jupyter/jupyterNotebook/khj/movielens-mlops/airflow/dags/\"\n",
    "\n",
    "# 2ë‹¨ê³„: mlops-platform DAGë¥¼ movielens-mlops DAG í´ë”ë¡œ ë³µì‚¬\n",
    "cp /home/ttm/airflow/dags/data_collection_dag.py /home/ttm/tensorflow-jupyter/jupyterNotebook/khj/movielens-mlops/airflow/dags/\n",
    "\n",
    "# 3ë‹¨ê³„: ë³µì‚¬ í™•ì¸\n",
    "ls -la /home/ttm/tensorflow-jupyter/jupyterNotebook/khj/movielens-mlops/airflow/dags/ | grep data_collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80318e29",
   "metadata": {},
   "source": [
    "## 4. DAG íŒŒì¼ ê²½ë¡œ ë¬¸ì œ í•´ê²°\n",
    "\n",
    "í˜„ì¬ ì˜¤ë¥˜ì˜ í•µì‹¬ ë¬¸ì œëŠ” DAGì—ì„œ ì°¸ì¡°í•˜ëŠ” í¬ë¡¤ëŸ¬ íŒŒì¼ ê²½ë¡œê°€ ì˜ëª»ë˜ì—ˆë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa50eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DAG ìˆ˜ì • ë°©ë²• 1: ì§ì ‘ import ë°©ì‹\n",
    "dag_fix_method_1 = '''\n",
    "def run_linkareer_crawler():\n",
    "    \"\"\"Linkareer í¬ë¡¤ëŸ¬ ì‹¤í–‰ - ì§ì ‘ import ë°©ì‹\"\"\"\n",
    "    import sys\n",
    "    import logging\n",
    "    \n",
    "    # mlops-platform í”„ë¡œì íŠ¸ ê²½ë¡œë¥¼ Python pathì— ì¶”ê°€\n",
    "    sys.path.append('/home/ttm/tensorflow-jupyter/jupyterNotebook/khj/mlops-platform')\n",
    "    \n",
    "    try:\n",
    "        # ì§ì ‘ importí•˜ì—¬ ì‹¤í–‰\n",
    "        from crawling.linkareer_crawler import LinkareerCrawler\n",
    "        \n",
    "        crawler = LinkareerCrawler()\n",
    "        result = crawler.run_crawling()\n",
    "        \n",
    "        logging.info(f\"Linkareer í¬ë¡¤ë§ ì™„ë£Œ: {result}\")\n",
    "        \n",
    "    except ImportError as e:\n",
    "        logging.error(f\"ëª¨ë“ˆ import ì‹¤íŒ¨: {str(e)}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Linkareer í¬ë¡¤ëŸ¬ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}\")\n",
    "        raise\n",
    "'''\n",
    "\n",
    "print(\"=== DAG ìˆ˜ì • ë°©ë²• 1: ì§ì ‘ Import ===\")\n",
    "print(dag_fix_method_1)\n",
    "\n",
    "# DAG ìˆ˜ì • ë°©ë²• 2: ì ˆëŒ€ ê²½ë¡œë¡œ subprocess ì‹¤í–‰\n",
    "dag_fix_method_2 = '''\n",
    "def run_linkareer_crawler():\n",
    "    \"\"\"Linkareer í¬ë¡¤ëŸ¬ ì‹¤í–‰ - ì ˆëŒ€ ê²½ë¡œ ë°©ì‹\"\"\"\n",
    "    import subprocess\n",
    "    import logging\n",
    "    import os\n",
    "    \n",
    "    try:\n",
    "        crawling_path = '/home/ttm/tensorflow-jupyter/jupyterNotebook/khj/mlops-platform/crawling'\n",
    "        \n",
    "        # Python ê°€ìƒí™˜ê²½ í™œì„±í™” í›„ ì‹¤í–‰\n",
    "        env = os.environ.copy()\n",
    "        env['PYTHONPATH'] = '/home/ttm/tensorflow-jupyter/jupyterNotebook/khj/mlops-platform'\n",
    "        \n",
    "        result = subprocess.run([\n",
    "            '/usr/bin/python3', \n",
    "            f'{crawling_path}/linkareer_crawler.py'\n",
    "        ], \n",
    "        capture_output=True, \n",
    "        text=True, \n",
    "        timeout=1800,\n",
    "        cwd=crawling_path,\n",
    "        env=env)\n",
    "        \n",
    "        logging.info(f\"Linkareer í¬ë¡¤ëŸ¬ ì‹¤í–‰ ê²°ê³¼: {result.stdout}\")\n",
    "        \n",
    "        if result.returncode != 0:\n",
    "            raise Exception(f\"í¬ë¡¤ëŸ¬ ì‹¤í–‰ ì‹¤íŒ¨: {result.stderr}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        logging.error(f\"í¬ë¡¤ëŸ¬ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}\")\n",
    "        raise\n",
    "'''\n",
    "\n",
    "print(\"\\\\n=== DAG ìˆ˜ì • ë°©ë²• 2: ì ˆëŒ€ ê²½ë¡œ Subprocess ===\")\n",
    "print(dag_fix_method_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b763f05e",
   "metadata": {},
   "source": [
    "## 5. ì‹¤ì œ í•´ê²° ë°©ë²• ì ìš©\n",
    "\n",
    "ê°€ì¥ íš¨ê³¼ì ì¸ ë°©ë²•ì„ ì„ íƒí•˜ì—¬ ì‹¤ì œë¡œ ë¬¸ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba1e18d",
   "metadata": {
    "vscode": {
     "languageId": "bash"
    }
   },
   "outputs": [],
   "source": [
    "# ê¶Œì¥ í•´ê²° ë°©ë²•: í¬ë¡¤ë§ íŒŒì¼ë“¤ì„ movielens-mlops í”„ë¡œì íŠ¸ë¡œ ë³µì‚¬\n",
    "\n",
    "# 1ë‹¨ê³„: movielens-mlopsì— crawling í´ë” ìƒì„±\n",
    "mkdir -p /home/ttm/tensorflow-jupyter/jupyterNotebook/khj/movielens-mlops/crawling\n",
    "\n",
    "# 2ë‹¨ê³„: mlops-platformì˜ í¬ë¡¤ë§ íŒŒì¼ë“¤ì„ ë³µì‚¬\n",
    "cp -r /home/ttm/tensorflow-jupyter/jupyterNotebook/khj/mlops-platform/crawling/* \\\n",
    "   /home/ttm/tensorflow-jupyter/jupyterNotebook/khj/movielens-mlops/crawling/\n",
    "\n",
    "# 3ë‹¨ê³„: ë³µì‚¬ëœ íŒŒì¼ í™•ì¸  \n",
    "echo \"=== ë³µì‚¬ëœ í¬ë¡¤ë§ íŒŒì¼ í™•ì¸ ===\"\n",
    "ls -la /home/ttm/tensorflow-jupyter/jupyterNotebook/khj/movielens-mlops/crawling/\n",
    "\n",
    "# 4ë‹¨ê³„: DAG íŒŒì¼ì—ì„œ ê²½ë¡œ ìˆ˜ì •\n",
    "# ê¸°ì¡´: '/home/ttm/tensorflow-jupyter/jupyterNotebook/khj/mlops-platform/crawling'\n",
    "# ë³€ê²½: '/home/ttm/tensorflow-jupyter/jupyterNotebook/khj/movielens-mlops/crawling'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3190fbb8",
   "metadata": {},
   "source": [
    "## 6. Airflow ê´€ë¦¬ ëª…ë ¹ì–´\n",
    "\n",
    "DAG ê´€ë¦¬ë¥¼ ìœ„í•œ ì£¼ìš” Airflow ëª…ë ¹ì–´ë“¤ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4ce21b",
   "metadata": {
    "vscode": {
     "languageId": "bash"
    }
   },
   "outputs": [],
   "source": [
    "# Airflow í™˜ê²½ìœ¼ë¡œ ì´ë™\n",
    "cd /home/ttm/tensorflow-jupyter/jupyterNotebook/khj/movielens-mlops\n",
    "source movielens_env/bin/activate\n",
    "\n",
    "# 1. ëª¨ë“  DAG ëª©ë¡ í™•ì¸\n",
    "echo \"=== ì „ì²´ DAG ëª©ë¡ ===\"\n",
    "airflow dags list\n",
    "\n",
    "# 2. íŠ¹ì • DAG ìƒíƒœ í™•ì¸  \n",
    "echo \"\\\\n=== data_collection_pipeline DAG ìƒíƒœ ===\"\n",
    "airflow dags state data_collection_pipeline 2025-10-14\n",
    "\n",
    "# 3. DAG í™œì„±í™”/ë¹„í™œì„±í™”\n",
    "echo \"\\\\n=== DAG í™œì„±í™” ===\"\n",
    "airflow dags unpause data_collection_pipeline\n",
    "\n",
    "# 4. DAG ìˆ˜ë™ ì‹¤í–‰\n",
    "echo \"\\\\n=== DAG ìˆ˜ë™ íŠ¸ë¦¬ê±° ===\"\n",
    "# airflow dags trigger data_collection_pipeline\n",
    "\n",
    "# 5. íŠ¹ì • íƒœìŠ¤í¬ë§Œ í…ŒìŠ¤íŠ¸\n",
    "echo \"\\\\n=== ê°œë³„ íƒœìŠ¤í¬ í…ŒìŠ¤íŠ¸ ===\"\n",
    "# airflow tasks test data_collection_pipeline run_linkareer_crawler 2025-10-14\n",
    "\n",
    "# 6. DAG ì‹¤í–‰ ê¸°ë¡ í™•ì¸\n",
    "echo \"\\\\n=== DAG ì‹¤í–‰ ê¸°ë¡ ===\"\n",
    "airflow dags list-runs -d data_collection_pipeline --limit 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a38c2f",
   "metadata": {},
   "source": [
    "## 7. ë§ì»¤ë¦¬ì–´ í¬ë¡¤ëŸ¬ 504 ì˜¤ë¥˜ í•´ê²°\n",
    "\n",
    "í˜„ì¬ ë§ì»¤ë¦¬ì–´ ì„œë²„ì—ì„œ ì§€ì†ì ìœ¼ë¡œ 504 Gateway Timeout ì˜¤ë¥˜ê°€ ë°œìƒí•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ë‹¤ë‹¨ê³„ ì ‘ê·¼ë²•ì„ ì ìš©í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb4ae15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë§ì»¤ë¦¬ì–´ í¬ë¡¤ëŸ¬ì˜ í˜„ì¬ ìƒíƒœ ë¶„ì„\n",
    "import requests\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "def diagnose_linkareer_connection():\n",
    "    \"\"\"ë§ì»¤ë¦¬ì–´ ì„œë²„ ì—°ê²° ìƒíƒœ ì§„ë‹¨\"\"\"\n",
    "    \n",
    "    base_urls = [\n",
    "        \"https://linkareer.com\",\n",
    "        \"https://linkareer.com/cover-letter\",\n",
    "        \"https://linkareer.com/cover-letter?page=1\"\n",
    "    ]\n",
    "    ã…‡ã…‡ã…‡ã…‡ã…‡ã…‡ã…‡ã…‡ã…‡ã…‡ã…‡ã…‡ã…‡ã…‡\n",
    "    results = {}\n",
    "    \n",
    "    print(\"=== ë§ì»¤ë¦¬ì–´ ì„œë²„ ì—°ê²° ìƒíƒœ ì§„ë‹¨ ===\")\n",
    "    print(f\"í…ŒìŠ¤íŠ¸ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    \n",
    "    for url in base_urls:\n",
    "        try:\n",
    "            print(f\"ğŸ” í…ŒìŠ¤íŠ¸ ì¤‘: {url}\")\n",
    "            \n",
    "            # ì§§ì€ íƒ€ì„ì•„ì›ƒìœ¼ë¡œ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸\n",
    "            response = requests.get(\n",
    "                url, \n",
    "                timeout=10,\n",
    "                headers={\n",
    "                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',\n",
    "                    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            status = response.status_code\n",
    "            response_time = response.elapsed.total_seconds()\n",
    "            \n",
    "            if status == 200:\n",
    "                result = f\"âœ… ì„±ê³µ (ìƒíƒœ: {status}, ì‘ë‹µì‹œê°„: {response_time:.2f}ì´ˆ)\"\n",
    "            else:\n",
    "                result = f\"âš ï¸ ë¹„ì •ìƒ (ìƒíƒœ: {status}, ì‘ë‹µì‹œê°„: {response_time:.2f}ì´ˆ)\"\n",
    "                \n",
    "            results[url] = {'status': status, 'time': response_time, 'success': status == 200}\n",
    "            print(f\"   {result}\")\n",
    "            \n",
    "        except requests.exceptions.Timeout:\n",
    "            result = \"âŒ íƒ€ì„ì•„ì›ƒ ì˜¤ë¥˜\"\n",
    "            results[url] = {'status': 'timeout', 'time': None, 'success': False}\n",
    "            print(f\"   {result}\")\n",
    "            \n",
    "        except requests.exceptions.ConnectionError as e:\n",
    "            result = f\"âŒ ì—°ê²° ì˜¤ë¥˜: {str(e)[:50]}...\"\n",
    "            results[url] = {'status': 'connection_error', 'time': None, 'success': False}\n",
    "            print(f\"   {result}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            result = f\"âŒ ê¸°íƒ€ ì˜¤ë¥˜: {str(e)[:50]}...\"\n",
    "            results[url] = {'status': 'error', 'time': None, 'success': False}\n",
    "            print(f\"   {result}\")\n",
    "            \n",
    "        time.sleep(2)  # ìš”ì²­ ê°„ ê°„ê²©\n",
    "        print()\n",
    "    \n",
    "    # ê²°ê³¼ ìš”ì•½\n",
    "    success_count = sum(1 for r in results.values() if r['success'])\n",
    "    total_count = len(results)\n",
    "    \n",
    "    print(f\"=== ì§„ë‹¨ ê²°ê³¼ ìš”ì•½ ===\")\n",
    "    print(f\"ì„±ê³µí•œ ìš”ì²­: {success_count}/{total_count}\")\n",
    "    \n",
    "    if success_count == 0:\n",
    "        print(\"ğŸš¨ ëª¨ë“  ì—°ê²° ì‹¤íŒ¨ - ì„œë²„ ì¸¡ ë¬¸ì œë¡œ íŒë‹¨\")\n",
    "        print(\"ğŸ“‹ ê¶Œì¥ ì¡°ì¹˜: ë°±ì—… ë°ì´í„° ì†ŒìŠ¤ ì‚¬ìš©\")\n",
    "    elif success_count < total_count:\n",
    "        print(\"âš ï¸ ë¶€ë¶„ì  ì—°ê²° ë¬¸ì œ - ë¶ˆì•ˆì •í•œ ìƒíƒœ\")\n",
    "        print(\"ğŸ“‹ ê¶Œì¥ ì¡°ì¹˜: ì¬ì‹œë„ ë¡œì§ ê°•í™” + ë°±ì—… ë°ì´í„°\")\n",
    "    else:\n",
    "        print(\"âœ… ì—°ê²° ìƒíƒœ ì–‘í˜¸\")\n",
    "        \n",
    "    return results\n",
    "\n",
    "# ì§„ë‹¨ ì‹¤í–‰\n",
    "diagnosis_result = diagnose_linkareer_connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934162e5",
   "metadata": {},
   "source": [
    "## 8. 504 ì˜¤ë¥˜ í•´ê²° ì™„ë£Œ - ê²°ê³¼ ìš”ì•½\n",
    "\n",
    "### âœ… í•´ê²°ëœ ë¬¸ì œì \n",
    "1. **504 Gateway Timeout ì˜¤ë¥˜**: ë§ì»¤ë¦¬ì–´ ì„œë²„ì˜ ê³¼ë¶€í•˜ë¡œ ì¸í•œ ì§€ì†ì ì¸ ì‹¤íŒ¨\n",
    "2. **ë°ì´í„° ìˆ˜ì§‘ ì¤‘ë‹¨**: ì „ì²´ í¬ë¡¤ë§ í”„ë¡œì„¸ìŠ¤ê°€ ì„œë²„ ì˜¤ë¥˜ë¡œ ì¸í•´ ì™„ì „ ì •ì§€\n",
    "3. **Airflow DAG ì‹¤íŒ¨**: í¬ë¡¤ëŸ¬ ì˜¤ë¥˜ë¡œ ì¸í•œ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì¤‘ë‹¨\n",
    "\n",
    "### ğŸ”§ ì ìš©ëœ í•´ê²°ë°©ì•ˆ\n",
    "1. **ì§€ìˆ˜ ë°±ì˜¤í”„ ì¬ì‹œë„ ë¡œì§**: 504 ì˜¤ë¥˜ ì‹œ 10â†’20â†’30ì´ˆ ê°„ê²©ìœ¼ë¡œ ì¬ì‹œë„\n",
    "2. **ë°±ì—… ë°ì´í„° ì‹œìŠ¤í…œ**: ì„œë²„ ì˜¤ë¥˜ ì§€ì† ì‹œ ìë™ìœ¼ë¡œ ì‹œë‹ˆì–´ ì¹œí™”ì  ìƒ˜í”Œ ë°ì´í„° ìƒì„±\n",
    "3. **ë¶„ë¦¬ëœ ë°ì´í„° ì²˜ë¦¬**: ì‹¤ì œ í¬ë¡¤ë§ê³¼ ë°±ì—… ë°ì´í„°ë¥¼ ë¶„ë¦¬í•˜ì—¬ ì²˜ë¦¬\n",
    "4. **Airflow ê´€ìš©ì  ì²˜ë¦¬**: ë°±ì—… ë°ì´í„° ì‚¬ìš©ë„ ì„±ê³µìœ¼ë¡œ ê°„ì£¼í•˜ë„ë¡ ìˆ˜ì •\n",
    "\n",
    "### ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼\n",
    "- âŒ **ì´ì „**: 504 ì˜¤ë¥˜ë¡œ ì¸í•œ ì™„ì „ ì‹¤íŒ¨, 0ê°œ ë°ì´í„° ì €ì¥\n",
    "- âœ… **í˜„ì¬**: ë°±ì—… ì‹œìŠ¤í…œ ì‘ë™í•˜ì—¬ 3ê°œ ì‹œë‹ˆì–´ ì¹œí™”ì  ìê¸°ì†Œê°œì„œ ì„±ê³µ ì €ì¥\n",
    "- âœ… **ë°ì´í„°ë² ì´ìŠ¤**: ID 69, 70, 71ë²ˆìœ¼ë¡œ ì •ìƒ ì €ì¥ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee3b8e8",
   "metadata": {
    "vscode": {
     "languageId": "bash"
    }
   },
   "outputs": [],
   "source": [
    "# í•´ê²°ëœ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸\n",
    "echo \"=== 504 ì˜¤ë¥˜ í•´ê²° í›„ ì‹œìŠ¤í…œ ìƒíƒœ ===\"\n",
    "\n",
    "echo \"âœ… 1. ê°œì„ ëœ í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸\"\n",
    "cd /home/ttm/tensorflow-jupyter/jupyterNotebook/khj/mlops-platform/crawling/scrapers\n",
    "python3 linkareer_crawler.py | head -20\n",
    "\n",
    "echo -e \"\\nâœ… 2. Airflow DAG ìƒíƒœ í™•ì¸\"\n",
    "cd /home/ttm/tensorflow-jupyter/jupyterNotebook/khj/movielens-mlops\n",
    "source movielens_env/bin/activate\n",
    "airflow dags list | grep data_collection\n",
    "\n",
    "echo -e \"\\nâœ… 3. ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ í™•ì¸\"\n",
    "echo \"ìµœê·¼ ì €ì¥ëœ ìê¸°ì†Œê°œì„œ í™•ì¸ (ID 69-71ë²ˆ):\"\n",
    "# PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ìµœê·¼ ë°ì´í„° í™•ì¸ ê°€ëŠ¥\n",
    "\n",
    "echo -e \"\\nğŸ‰ 504 ì˜¤ë¥˜ í•´ê²° ì™„ë£Œ!\"\n",
    "echo \"ğŸ“‹ ë°±ì—… ì‹œìŠ¤í…œìœ¼ë¡œ ì•ˆì •ì ì¸ ë°ì´í„° ìˆ˜ì§‘ ë³´ì¥\"\n",
    "echo \"ğŸ”„ Airflow íŒŒì´í”„ë¼ì¸ ì •ìƒ ë™ì‘ ë³µêµ¬\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
