import React, { useState, useRef, useEffect } from 'react';
import {
  Box,
  Button,
  Typography,
  Paper,
  Alert,
  CircularProgress,
  LinearProgress
} from '@mui/material';
import {
  Mic,
  Stop,
  PlayArrow,
  Pause
} from '@mui/icons-material';

interface VoiceRecorderProps {
  onRecordingComplete: (audioBlob: Blob, transcript?: string) => void;
  maxDuration?: number; // ì´ˆ ë‹¨ìœ„
  autoTranscribe?: boolean;
}

const VoiceRecorder: React.FC<VoiceRecorderProps> = ({
  onRecordingComplete,
  maxDuration = 300, // ê¸°ë³¸ 5ë¶„
  autoTranscribe = true
}) => {
  const [isRecording, setIsRecording] = useState(false);
  const [isPaused, setIsPaused] = useState(false);
  const [isPlaying, setIsPlaying] = useState(false);
  const [recordingTime, setRecordingTime] = useState(0);
  const [audioBlob, setAudioBlob] = useState<Blob | null>(null);
  const [audioUrl, setAudioUrl] = useState<string | null>(null);
  const [error, setError] = useState<string | null>(null);
  const [isTranscribing, setIsTranscribing] = useState(false);

  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const timerRef = useRef<NodeJS.Timeout | null>(null);
  const audioRef = useRef<HTMLAudioElement | null>(null);

  useEffect(() => {
    return () => {
      // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬
      if (timerRef.current) {
        clearInterval(timerRef.current);
      }
      if (audioUrl) {
        URL.revokeObjectURL(audioUrl);
      }
    };
  }, [audioUrl]);

  const startRecording = async () => {
    try {
      setError(null);
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      
      const mediaRecorder = new MediaRecorder(stream);
      mediaRecorderRef.current = mediaRecorder;
      audioChunksRef.current = [];

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
        }
      };

      mediaRecorder.onstop = () => {
        const blob = new Blob(audioChunksRef.current, { type: 'audio/webm' });
        setAudioBlob(blob);
        const url = URL.createObjectURL(blob);
        setAudioUrl(url);
        
        // ìŠ¤íŠ¸ë¦¼ ì •ë¦¬
        stream.getTracks().forEach(track => track.stop());
      };

      mediaRecorder.start();
      setIsRecording(true);
      setRecordingTime(0);

      // íƒ€ì´ë¨¸ ì‹œì‘
      timerRef.current = setInterval(() => {
        setRecordingTime(prev => {
          const newTime = prev + 1;
          if (newTime >= maxDuration) {
            stopRecording();
            return maxDuration;
          }
          return newTime;
        });
      }, 1000);

    } catch (err) {
      console.error('ë§ˆì´í¬ ì ‘ê·¼ ì˜¤ë¥˜:', err);
      setError('ë§ˆì´í¬ì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë§ˆì´í¬ ê¶Œí•œì„ í™•ì¸í•´ ì£¼ì„¸ìš”.');
    }
  };

  const stopRecording = () => {
    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop();
      setIsRecording(false);
      setIsPaused(false);
      
      if (timerRef.current) {
        clearInterval(timerRef.current);
        timerRef.current = null;
      }
    }
  };

  const pauseRecording = () => {
    if (mediaRecorderRef.current && isRecording) {
      if (isPaused) {
        mediaRecorderRef.current.resume();
        setIsPaused(false);
      } else {
        mediaRecorderRef.current.pause();
        setIsPaused(true);
      }
    }
  };

  const playAudio = () => {
    if (audioRef.current && audioUrl) {
      if (isPlaying) {
        audioRef.current.pause();
        setIsPlaying(false);
      } else {
        audioRef.current.play();
        setIsPlaying(true);
      }
    }
  };

  const handleComplete = async () => {
    if (!audioBlob) return;

    if (autoTranscribe) {
      setIsTranscribing(true);
      try {
        // ì—¬ê¸°ì„œ ì‹¤ì œ STT API í˜¸ì¶œ
        // const formData = new FormData();
        // formData.append('file', audioBlob);
        // const response = await axios.post('/api/speech/transcribe', formData);
        // onRecordingComplete(audioBlob, response.data.text);
        
        // ì„ì‹œë¡œ ë°”ë¡œ ì „ë‹¬
        onRecordingComplete(audioBlob);
      } catch (err) {
        console.error('ìŒì„± ë³€í™˜ ì˜¤ë¥˜:', err);
        setError('ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
      } finally {
        setIsTranscribing(false);
      }
    } else {
      onRecordingComplete(audioBlob);
    }
  };

  const formatTime = (seconds: number): string => {
    const mins = Math.floor(seconds / 60);
    const secs = seconds % 60;
    return `${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`;
  };

  const progress = (recordingTime / maxDuration) * 100;

  return (
    <Paper 
      elevation={3} 
      sx={{ 
        p: 4, 
        textAlign: 'center',
        backgroundColor: 'background.paper'
      }}
    >
      <Typography 
        variant="h5" 
        gutterBottom
        sx={{ fontSize: '1.5rem', fontWeight: 600, mb: 3 }}
      >
        ìŒì„± ë…¹ìŒ
      </Typography>

      {error && (
        <Alert severity="error" sx={{ mb: 3, fontSize: '1.1rem' }}>
          {error}
        </Alert>
      )}

      <Box sx={{ mb: 4 }}>
        <Typography 
          variant="h3" 
          sx={{ 
            fontSize: '3rem', 
            fontWeight: 'bold',
            color: isRecording ? 'error.main' : 'text.primary',
            mb: 2
          }}
        >
          {formatTime(recordingTime)}
        </Typography>

        {isRecording && (
          <Box sx={{ mb: 2 }}>
            <LinearProgress 
              variant="determinate" 
              value={progress}
              sx={{ height: 10, borderRadius: 5 }}
            />
            <Typography 
              variant="body2" 
              color="text.secondary"
              sx={{ mt: 1, fontSize: '1rem' }}
            >
              ìµœëŒ€ {formatTime(maxDuration)} ê¹Œì§€ ë…¹ìŒ ê°€ëŠ¥
            </Typography>
          </Box>
        )}
      </Box>

      <Box sx={{ display: 'flex', gap: 2, justifyContent: 'center', mb: 3 }}>
        {!isRecording && !audioBlob && (
          <Button
            variant="contained"
            color="error"
            size="large"
            startIcon={<Mic />}
            onClick={startRecording}
            sx={{ 
              fontSize: '1.2rem',
              py: 2,
              px: 4,
              minHeight: '60px',
              minWidth: '200px'
            }}
          >
            ë…¹ìŒ ì‹œì‘
          </Button>
        )}

        {isRecording && (
          <>
            <Button
              variant="contained"
              color={isPaused ? 'primary' : 'warning'}
              size="large"
              startIcon={isPaused ? <PlayArrow /> : <Pause />}
              onClick={pauseRecording}
              sx={{ 
                fontSize: '1.2rem',
                py: 2,
                px: 3,
                minHeight: '60px'
              }}
            >
              {isPaused ? 'ê³„ì†' : 'ì¼ì‹œì •ì§€'}
            </Button>
            <Button
              variant="contained"
              color="error"
              size="large"
              startIcon={<Stop />}
              onClick={stopRecording}
              sx={{ 
                fontSize: '1.2rem',
                py: 2,
                px: 3,
                minHeight: '60px'
              }}
            >
              ì •ì§€
            </Button>
          </>
        )}

        {audioBlob && (
          <>
            <Button
              variant="outlined"
              size="large"
              startIcon={isPlaying ? <Pause /> : <PlayArrow />}
              onClick={playAudio}
              sx={{ 
                fontSize: '1.2rem',
                py: 2,
                px: 3,
                minHeight: '60px'
              }}
            >
              {isPlaying ? 'ì¼ì‹œì •ì§€' : 'ì¬ìƒ'}
            </Button>
            <Button
              variant="outlined"
              size="large"
              startIcon={<Mic />}
              onClick={() => {
                setAudioBlob(null);
                setAudioUrl(null);
                setRecordingTime(0);
              }}
              sx={{ 
                fontSize: '1.2rem',
                py: 2,
                px: 3,
                minHeight: '60px'
              }}
            >
              ë‹¤ì‹œ ë…¹ìŒ
            </Button>
          </>
        )}
      </Box>

      {audioBlob && (
        <Button
          variant="contained"
          color="primary"
          size="large"
          onClick={handleComplete}
          disabled={isTranscribing}
          sx={{ 
            fontSize: '1.3rem',
            py: 2.5,
            px: 5,
            minHeight: '70px',
            minWidth: '250px'
          }}
        >
          {isTranscribing ? (
            <>
              <CircularProgress size={24} sx={{ mr: 2 }} />
              ìŒì„± ë³€í™˜ ì¤‘...
            </>
          ) : (
            'ì´ë ¥ì„œ ìƒì„±í•˜ê¸°'
          )}
        </Button>
      )}

      {audioUrl && (
        <audio
          ref={audioRef}
          src={audioUrl}
          onEnded={() => setIsPlaying(false)}
          style={{ display: 'none' }}
        />
      )}

      <Box sx={{ mt: 4, p: 2, backgroundColor: 'info.lighter', borderRadius: 2 }}>
        <Typography 
          variant="body1" 
          color="info.dark"
          sx={{ fontSize: '1.1rem', lineHeight: 1.6 }}
        >
          ğŸ’¡ <strong>íŒ:</strong> ì¡°ìš©í•œ ê³³ì—ì„œ ë§ˆì´í¬ì— ëŒ€ê³  ë˜ë°•ë˜ë°• ë§ì”€í•´ ì£¼ì„¸ìš”.
          <br />
          ê²½ë ¥, í•™ë ¥, ê¸°ìˆ  ë“± ì´ë ¥ì„œì— ë“¤ì–´ê°ˆ ë‚´ìš©ì„ ììœ ë¡­ê²Œ ë§ì”€í•˜ì‹œë©´ ë©ë‹ˆë‹¤.
        </Typography>
      </Box>
    </Paper>
  );
};

export default VoiceRecorder;
